{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y-k3gLY-dCQ",
    "outputId": "859e5af1-3238-48dc-d608-9c22f51ff214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH1PEMvaIjCe",
    "outputId": "e6d249fe-3c57-4ac3-9c20-e23010359cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LightGlue'...\n",
      "remote: Enumerating objects: 386, done.\u001b[K\n",
      "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
      "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
      "remote: Total 386 (delta 144), reused 80 (delta 80), pack-reused 184 (from 2)\u001b[K\n",
      "Receiving objects: 100% (386/386), 17.43 MiB | 30.45 MiB/s, done.\n",
      "Resolving deltas: 100% (236/236), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/cvg/LightGlue.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivUrqxGDQ06i",
    "outputId": "7c49c2d1-6502-44c0-db00-dcca45d35c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/LightGlue\n"
     ]
    }
   ],
   "source": [
    "cd LightGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYJYSWIyQ080",
    "outputId": "78adfe52-bc23-43d3-acd2-03f8d3b00b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/LightGlue\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from lightglue==0.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.3 in /usr/local/lib/python3.11/dist-packages (from lightglue==0.0) (0.21.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightglue==0.0) (2.0.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from lightglue==0.0) (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lightglue==0.0) (3.10.0)\n",
      "Collecting kornia>=0.6.11 (from lightglue==0.0)\n",
      "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting kornia_rs>=0.1.9 (from kornia>=0.6.11->lightglue==0.0)\n",
      "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia>=0.6.11->lightglue==0.0) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.1->lightglue==0.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->lightglue==0.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.1->lightglue==0.0) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.3->lightglue==0.0) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lightglue==0.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lightglue==0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lightglue==0.0) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lightglue==0.0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lightglue==0.0) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lightglue==0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lightglue==0.0) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->lightglue==0.0) (3.0.2)\n",
      "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lightglue\n",
      "  Building editable for lightglue (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lightglue: filename=lightglue-0.0-0.editable-py3-none-any.whl size=14711 sha256=fcf046b88bce374509ff8366351accdd96b8b5eb12c99189f38429fe8e163ba8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nbx384tb/wheels/d7/46/ba/de4c4db2fb4999cf8b06458bcdd1d076d6c5458e0cc1b9462c\n",
      "Successfully built lightglue\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, kornia_rs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kornia, lightglue\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed kornia-0.8.1 kornia_rs-0.1.9 lightglue-0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pG8AqflWXgp",
    "outputId": "63a09179-aa5d-4d1b-941d-5bc16f9d6d51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/LightGlue/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "from lightglue import LightGlue, SuperPoint, DISK, SIFT, ALIKED, DoGHardNet\n",
    "from lightglue.utils import load_image, rbd\n",
    "plt.rcParams['figure.figsize'] = [15, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THnKjlB3Q69s",
    "outputId": "78d5af51-e37c-41cb-a49b-025c16189616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48tGnOUWQ8oN",
    "outputId": "6854467e-105b-4b25-c9f5-2b5f9a9b2798"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/sift_lightglue.pth\" to /root/.cache/torch/hub/checkpoints/sift_lightglue_v0-1_arxiv.pth\n",
      "100%|██████████| 45.4M/45.4M [00:00<00:00, 184MB/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------SUPERPOINT----------------------------\n",
    "#  Optimized\n",
    "# extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()  # load the extractor\n",
    "# matcher = LightGlue(features='superpoint').eval().cuda()  # load the matcher\n",
    "\n",
    "# Full accuracy\n",
    "# extractor = SuperPoint(max_num_keypoints=None).cuda()\n",
    "# matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "# Full speed\n",
    "# extractor = SuperPoint(max_num_keypoints=1024).cuda()\n",
    "# matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "# ---------------------DISK----------------------------\n",
    "#  Optimized\n",
    "# extractor = DISK(max_num_keypoints=2048).eval().cuda()\n",
    "# matcher = LightGlue(features='disk').cuda()\n",
    "\n",
    "# Full accuracy\n",
    "# extractor = DISK(max_num_keypoints=None).eval().cuda()\n",
    "# matcher = LightGlue(features='disk', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "# Full speed\n",
    "# extractor = DISK(max_num_keypoints=1024).eval().cuda()\n",
    "# matcher = LightGlue(features='disk', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "# ---------------------SIFT----------------------------\n",
    "#  Optimized\n",
    "# extractor = SIFT(max_num_keypoints=2048).eval().cuda()\n",
    "# matcher = LightGlue(features='sift').cuda()\n",
    "\n",
    "# Full accuracy\n",
    "# extractor = SIFT(max_num_keypoints=None).eval().cuda()\n",
    "# matcher = LightGlue(features='sift', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "# Full speed\n",
    "# extractor = SIFT(max_num_keypoints=1024).eval().cuda()\n",
    "# matcher = LightGlue(features='sift', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "# ---------------------ALIKED----------------------------\n",
    "#  Optimized\n",
    "# extractor = ALIKED(max_num_keypoints=2048).eval().cuda()\n",
    "# matcher = LightGlue(features='aliked').cuda()\n",
    "\n",
    "# Full accuracy\n",
    "# extractor = ALIKED(max_num_keypoints=None).eval().cuda()\n",
    "# matcher = LightGlue(features='aliked', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "# Full speed\n",
    "# extractor = ALIKED(max_num_keypoints=1024).eval().cuda()\n",
    "# matcher = LightGlue(features='aliked', depth_confidence=0.9, width_confidence=0.95).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBMYwmvpXV_2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read image, convert to gray, and resize based on resize factor\n",
    "def read_image(path, resize=1.0):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found at path: {path}\")\n",
    "\n",
    "    # Resize image if resize factor is less than 1\n",
    "    if 0 < resize < 1.0:\n",
    "        h, w = img.shape[:2]\n",
    "        new_size = (int(w * resize), int(h * resize))\n",
    "        img = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img_gray, img, img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg30VA37XWHm"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def homography(pairs):\n",
    "    rows = []\n",
    "    for i in range(pairs.shape[0]):\n",
    "        p1 = np.append(pairs[i][0:2], 1)\n",
    "        p2 = np.append(pairs[i][2:4], 1)\n",
    "        row1 = [0, 0, 0, p1[0], p1[1], p1[2], -p2[1]*p1[0], -p2[1]*p1[1], -p2[1]*p1[2]]\n",
    "        row2 = [p1[0], p1[1], p1[2], 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1], -p2[0]*p1[2]]\n",
    "        rows.append(row1)\n",
    "        rows.append(row2)\n",
    "    rows = np.array(rows)\n",
    "    U, s, V = np.linalg.svd(rows)\n",
    "    H = V[-1].reshape(3, 3)\n",
    "    H = H/H[2, 2] # standardize to let w*H[2,2] = 1\n",
    "    return H\n",
    "\n",
    "def random_point(matches, k=4):\n",
    "    idx = random.sample(range(len(matches)), k)\n",
    "    point = [matches[i] for i in idx ]\n",
    "    return np.array(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8dxyOAqYjwX"
   },
   "outputs": [],
   "source": [
    "def random_point(matches, k=4):\n",
    "    idx = random.sample(range(len(matches)), k)\n",
    "    point = [matches[i] for i in idx ]\n",
    "    return np.array(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYGqF3S3Yjyw"
   },
   "outputs": [],
   "source": [
    "def get_error(points, H):\n",
    "    num_points = len(points)\n",
    "    all_p1 = np.concatenate((points[:, 0:2], np.ones((num_points, 1))), axis=1)\n",
    "    all_p2 = points[:, 2:4]\n",
    "    estimate_p2 = np.zeros((num_points, 2))\n",
    "    for i in range(num_points):\n",
    "        temp = np.dot(H, all_p1[i])\n",
    "        estimate_p2[i] = (temp/temp[2])[0:2] # set index 2 to 1 and slice the index 0, 1\n",
    "    # Compute error\n",
    "    errors = np.linalg.norm(all_p2 - estimate_p2 , axis=1) ** 2\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca5B0KEZYj01"
   },
   "outputs": [],
   "source": [
    "def ransac(matches, threshold, iters):\n",
    "    num_best_inliers = 0\n",
    "\n",
    "    for i in range(iters):\n",
    "        points = random_point(matches)\n",
    "        H = homography(points)\n",
    "\n",
    "        #  avoid dividing by zero\n",
    "        if np.linalg.matrix_rank(H) < 3:\n",
    "            continue\n",
    "\n",
    "        errors = get_error(matches, H)\n",
    "        idx = np.where(errors < threshold)[0]\n",
    "        inliers = matches[idx]\n",
    "\n",
    "        num_inliers = len(inliers)\n",
    "        if num_inliers > num_best_inliers:\n",
    "            best_inliers = inliers.copy()\n",
    "            num_best_inliers = num_inliers\n",
    "            best_H = H.copy()\n",
    "\n",
    "    print(\"inliers/matches: {}/{}\".format(num_best_inliers, len(matches)))\n",
    "    return best_inliers, best_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4Jo0_6IYnGC"
   },
   "outputs": [],
   "source": [
    "def stitch_img(left, right, H):\n",
    "    # print(\"Stitching image ...\")\n",
    "\n",
    "    # Normalize images to float in [0,1]\n",
    "    left = cv2.normalize(left.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    right = cv2.normalize(right.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    height_l, width_l, _ = left.shape\n",
    "    height_r, width_r, _ = right.shape\n",
    "\n",
    "    # Compute corners for the left image and transform them using H\n",
    "    corners_left = np.array([[0, 0, 1],\n",
    "                             [width_l, 0, 1],\n",
    "                             [width_l, height_l, 1],\n",
    "                             [0, height_l, 1]]).T  # shape (3,4)\n",
    "    warped_corners_left = H @ corners_left\n",
    "    warped_corners_left /= warped_corners_left[2, :]  # Normalize homogeneous coordinates\n",
    "\n",
    "    # Compute corners for the right image (identity transform)\n",
    "    corners_right = np.array([[0, 0, 1],\n",
    "                              [width_r, 0, 1],\n",
    "                              [width_r, height_r, 1],\n",
    "                              [0, height_r, 1]]).T  # shape (3,4)\n",
    "\n",
    "    # Combine corners to find overall bounds\n",
    "    all_x = np.concatenate((warped_corners_left[0, :], corners_right[0, :]))\n",
    "    all_y = np.concatenate((warped_corners_left[1, :], corners_right[1, :]))\n",
    "\n",
    "    min_x, max_x = np.min(all_x), np.max(all_x)\n",
    "    min_y, max_y = np.min(all_y), np.max(all_y)\n",
    "\n",
    "    # Create a translation matrix to shift all images so that no coordinate is negative\n",
    "    tx = -min_x if min_x < 0 else 0\n",
    "    ty = -min_y if min_y < 0 else 0\n",
    "    translation_mat = np.array([[1, 0, tx],\n",
    "                                [0, 1, ty],\n",
    "                                [0, 0, 1]])\n",
    "\n",
    "    # New canvas size: use ceiling to ensure full coverage\n",
    "    width_new = int(np.ceil(max_x - min_x))\n",
    "    height_new = int(np.ceil(max_y - min_y))\n",
    "    size = (width_new, height_new)\n",
    "\n",
    "    # Warp left image with the composite transform: translation_mat @ H\n",
    "    warped_left = cv2.warpPerspective(left, translation_mat @ H, size)\n",
    "    # Warp right image with just the translation matrix (identity warp + translation)\n",
    "    warped_right = cv2.warpPerspective(right, translation_mat, size)\n",
    "\n",
    "    # Vectorized blending:\n",
    "    # Create masks where any channel is non-zero (assumed as non-black)\n",
    "    mask_left = np.any(warped_left != 0, axis=2)\n",
    "    mask_right = np.any(warped_right != 0, axis=2)\n",
    "\n",
    "    # Initialize the stitched image as black\n",
    "    stitch_image = np.zeros_like(warped_left)\n",
    "\n",
    "    # Pixels only from left image\n",
    "    only_left = mask_left & ~mask_right\n",
    "    stitch_image[only_left] = warped_left[only_left]\n",
    "\n",
    "    # Pixels only from right image\n",
    "    only_right = mask_right & ~mask_left\n",
    "    stitch_image[only_right] = warped_right[only_right]\n",
    "\n",
    "    # Pixels where both images contribute (average the pixel values)\n",
    "    both = mask_left & mask_right\n",
    "    stitch_image[both] = (warped_left[both] + warped_right[both]) / 2\n",
    "\n",
    "    return stitch_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNYgYojiROAo"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# if you haven’t already got a counter somewhere:\n",
    "kct = -50\n",
    "\n",
    "def torch_to_cv2_image(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a C×H×W RGB torch tensor (on CPU or CUDA) to a H×W×C BGR uint8 numpy array.\n",
    "    \"\"\"\n",
    "    if tensor.is_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    image = tensor.clone().detach()\n",
    "    # (C,H,W) -> (H,W,C)\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    # assume floats in [0,1] or ints in [0,255]\n",
    "    if image.dtype != np.uint8:\n",
    "        image = np.clip(image * 255, 0, 255).astype(np.uint8)\n",
    "    # RGB->BGR\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def keep_top_left_percent(image, k: float):\n",
    "    \"\"\"\n",
    "    Keep only the top and left k-percent of pixels (an upside-down 'L'), black out the rest.\n",
    "    Works on either\n",
    "      • numpy.ndarray (H×W×C BGR)  or\n",
    "      • torch.Tensor   (C×H×W RGB floats [0,1] or [0,255], on CPU or CUDA)\n",
    "    \"\"\"\n",
    "    global kct\n",
    "    # --- validate k ---\n",
    "    if not (0 < k <= 1):\n",
    "        raise ValueError(\"Parameter k must be a float between 0 and 1.\")\n",
    "\n",
    "    # --- branch on type ---\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        print(\"Is tensor\")\n",
    "        # tensor path: C×H×W\n",
    "        C, H, W = image.shape\n",
    "        top_h = math.ceil(k * H)\n",
    "        left_w = math.ceil(k * W)\n",
    "\n",
    "        # build mask on same device & dtype\n",
    "        mask2d = torch.zeros((H, W), dtype=image.dtype, device=image.device)\n",
    "        mask2d[:top_h, :] = 1\n",
    "        mask2d[:, :left_w] = 1\n",
    "\n",
    "        # expand to C×H×W\n",
    "        mask3d = mask2d.unsqueeze(0).expand(C, H, W)\n",
    "\n",
    "        # apply mask\n",
    "        out_t = image * mask3d\n",
    "\n",
    "        # save out as JPEG\n",
    "        cv2_img = torch_to_cv2_image(out_t)\n",
    "        kct += 1\n",
    "        cv2.imwrite(f\"{kct}.jpg\", cv2_img)\n",
    "\n",
    "        return out_t\n",
    "\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        print(\"Is not tensor!\")\n",
    "        # numpy path: H×W×C BGR\n",
    "        H, W = image.shape[:2]\n",
    "        top_h = math.ceil(k * H)\n",
    "        left_w = math.ceil(k * W)\n",
    "\n",
    "        mask = np.zeros((H, W), dtype=bool)\n",
    "        mask[:top_h, :] = True\n",
    "        mask[:, :left_w] = True\n",
    "\n",
    "        black = np.zeros_like(image)\n",
    "        out_np = np.where(mask[..., None], image, black)\n",
    "\n",
    "        kct += 1\n",
    "        cv2.imwrite(f\"{kct}.jpg\", out_np)\n",
    "\n",
    "        return out_np\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            f\"Unsupported image type {type(image)} – must be numpy.ndarray or torch.Tensor.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def resize_torch(image0, new_size):\n",
    "  # image0 is a C×H×W float tensor on CUDA\n",
    "  # 1) send to CPU and turn into a H×W×C NumPy array\n",
    "  np_img = image0.cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "  # 2) do your OpenCV resize\n",
    "  h, w = np_img.shape[:2]\n",
    "  new_w = (w * int(new_size * 10)) // 10\n",
    "  new_h = (h * int(new_size * 10)) // 10\n",
    "  resized_np = cv2.resize(np_img, (new_w, new_h))\n",
    "\n",
    "  # 3) (optional) turn back into a tensor, same dtype/device as before\n",
    "  return torch.from_numpy(resized_np).permute(2, 0, 1).to(image0.dtype).cuda()\n",
    "\n",
    "\n",
    "def crop_tensor_image(image: torch.Tensor, h1: int, w1: int, h2: int, w2: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Crop an image tensor based on bounding box coordinates.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Image tensor of shape (C, H, W), values in [0,1] or [0,255].\n",
    "        h1 (int): Top coordinate (inclusive).\n",
    "        w1 (int): Left coordinate (inclusive).\n",
    "        h2 (int): Bottom coordinate (exclusive).\n",
    "        w2 (int): Right coordinate (exclusive).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Cropped image tensor of shape (C, h2-h1, w2-w1).\n",
    "    \"\"\"\n",
    "    if image.ndim != 3:\n",
    "        raise ValueError(\"Input image must be a 3D tensor (C, H, W)\")\n",
    "\n",
    "    C, H, W = image.shape\n",
    "\n",
    "    # Clamp coordinates to image boundaries\n",
    "    h1 = max(0, min(H, h1))\n",
    "    h2 = max(0, min(H, h2))\n",
    "    w1 = max(0, min(W, w1))\n",
    "    w2 = max(0, min(W, w2))\n",
    "\n",
    "    if h1 >= h2 or w1 >= w2:\n",
    "        raise ValueError(\"Invalid bounding box: (h1, w1) must be above and to the left of (h2, w2)\")\n",
    "\n",
    "    return image[:, h1:h2, w1:w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9Rho2ZkZ83K"
   },
   "outputs": [],
   "source": [
    "def plot_matches(matches, total_img, pos1=(0,0), pos2=(0,0)):\n",
    "    \"\"\"\n",
    "    matches: Nx4 array where each row is [x1, y1, x2, y2]\n",
    "    total_img: composite image with both images pasted on it.\n",
    "    pos1: (x, y) top-left position of image1 in total_img.\n",
    "    pos2: (x, y) top-left position of image2 in total_img.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(total_img.astype(np.uint8))\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Draw keypoints for image1 and image2 (adjusted by their positions)\n",
    "    pts1 = matches[:, :2] + np.array(pos1)\n",
    "    pts2 = matches[:, 2:] + np.array(pos2)\n",
    "    ax.plot(pts1[:, 0], pts1[:, 1], 'xr', markersize=5)\n",
    "    ax.plot(pts2[:, 0], pts2[:, 1], 'xr', markersize=5)\n",
    "\n",
    "    # Draw lines connecting the matching points\n",
    "    for (x1, y1), (x2, y2) in zip(pts1, pts2):\n",
    "        ax.plot([x1, x2], [y1, y2], 'r', linewidth=0.5)\n",
    "\n",
    "    plt.title(\"Feature Matches\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-Tkr27jJxOR",
    "outputId": "a083c097-104e-4691-b1a8-e43162c32c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0010.jpg\n",
      "image/0011.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def convert_image_number_base(filepath: str, b1: int, b2: int) -> str:\n",
    "    if not (1 <= b1 <= 10 and 1 <= b2 <= 10):\n",
    "        raise ValueError(\"Bases b1 and b2 must be between 1 and 10 (inclusive)\")\n",
    "\n",
    "    # Split into directory, filename, extension\n",
    "    dirname, filename = os.path.split(filepath)\n",
    "    name, ext = os.path.splitext(filename)\n",
    "\n",
    "    if ext.lower() not in ['.jpg', '.png']:\n",
    "        raise ValueError(\"File must be a .jpg or .png\")\n",
    "\n",
    "    # Ensure the number part is 4 digits\n",
    "    if not (len(name) == 4 and name.isdigit()):\n",
    "        raise ValueError(\"Filename must contain a 4-digit number\")\n",
    "\n",
    "    # Convert number from base b1 to int\n",
    "    try:\n",
    "        number = int(name, base=b1)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"The number '{name}' is not valid in base {b1}\")\n",
    "\n",
    "    # Convert from int to base b2\n",
    "    def to_base(n: int, base: int) -> str:\n",
    "        if n == 0:\n",
    "            return '0'\n",
    "        digits = []\n",
    "        while n:\n",
    "            digits.append(str(n % base))\n",
    "            n //= base\n",
    "        return ''.join(reversed(digits))\n",
    "\n",
    "    new_number = to_base(number, b2).zfill(4)\n",
    "    new_filename = new_number + ext\n",
    "    return os.path.join(dirname, new_filename) if dirname else new_filename\n",
    "\n",
    "print(convert_image_number_base('0005.jpg', 10, 5))         # '0010.jpg'\n",
    "print(convert_image_number_base('image/0006.png', 10, 5))   # 'image/0011.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xfl3D4r7GtS3"
   },
   "outputs": [],
   "source": [
    "def poz(matrix_size, i):\n",
    "  init_i = i\n",
    "\n",
    "  if i < 1:\n",
    "    return None\n",
    "  if i > (matrix_size * matrix_size) - 1:\n",
    "    return None\n",
    "\n",
    "  max_line = matrix_size - 1\n",
    "\n",
    "  diag_nr = 1\n",
    "  x = diag_nr\n",
    "  y = 0\n",
    "  prev_poz = 0, 0\n",
    "  while True:\n",
    "    i -= 1\n",
    "    if i == 0:\n",
    "      if init_i < ((matrix_size * (matrix_size + 1)) // 2):\n",
    "        prev_x, prev_y = prev_poz\n",
    "        if prev_x == 0:\n",
    "          return x, y, prev_x + prev_y + 1, prev_x + prev_y + 1\n",
    "        else:\n",
    "          return x, y, prev_x + prev_y + 1, prev_x + prev_y\n",
    "      return x, y, matrix_size, matrix_size\n",
    "\n",
    "    if i == 1:\n",
    "      prev_poz = x, y\n",
    "\n",
    "    if x == 0 or y == max_line:\n",
    "      diag_nr += 1\n",
    "\n",
    "      if diag_nr > max_line:\n",
    "        x = max_line\n",
    "        y = diag_nr - max_line\n",
    "      else:\n",
    "        x = diag_nr\n",
    "        y = 0\n",
    "    else:\n",
    "      x -= 1\n",
    "      y += 1\n",
    "\n",
    "def poz_list(path, paths):\n",
    "  max_0, max_1 = 0, 0\n",
    "  for path1 in paths:\n",
    "    if path == path1:\n",
    "      break\n",
    "    # path1 = convert_image_number_base(path1, 10, 5)\n",
    "    x, y = int(path1.split(\".jpg\")[0][2:][0]), int(path1.split(\".jpg\")[0][2:][1])\n",
    "    max_0 = max(max_0, x)\n",
    "    max_1 = max(max_1, y)\n",
    "  return int(path.split(\".jpg\")[0][2:][0]), int(path.split(\".jpg\")[0][2:][1]), max_0 + 1, max_1 + 1\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "def save_image(tensor: torch.Tensor, filename: str = \"image.png\"):\n",
    "    \"\"\"\n",
    "    Save a tensor as an image file.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Image tensor of shape (C, H, W).\n",
    "        filename (str): Path to save the image.\n",
    "    \"\"\"\n",
    "    # If the tensor is [0, 255] floats, normalize it to [0, 1]\n",
    "    if tensor.max() > 1.0:\n",
    "        tensor = tensor / 255.0\n",
    "\n",
    "    vutils.save_image(tensor, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3zgB5XHZS3A"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def detect_black_border_depths(image_pil, black_threshold=10):\n",
    "    \"\"\"\n",
    "    Detects how much black padding exists on each edge of the image separately.\n",
    "\n",
    "    Args:\n",
    "        image_pil: PIL.Image object (RGB or grayscale).\n",
    "        black_threshold: Maximum pixel value considered \"black\" (0-255).\n",
    "\n",
    "    Returns:\n",
    "        (top, bottom, left, right): number of black pixels to crop from each side.\n",
    "    \"\"\"\n",
    "    image_np = np.array(image_pil)\n",
    "\n",
    "    if image_np.ndim == 3:\n",
    "        # Convert to grayscale if RGB\n",
    "        image_np = np.mean(image_np, axis=2)\n",
    "\n",
    "    h, w = image_np.shape\n",
    "\n",
    "    # Initialize cropping values\n",
    "    top = 0\n",
    "    bottom = 0\n",
    "    left = 0\n",
    "    right = 0\n",
    "\n",
    "    # Detect top\n",
    "    for y in range(h):\n",
    "        if np.all(image_np[y, :] <= black_threshold):\n",
    "            top += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Detect bottom\n",
    "    for y in range(h-1, -1, -1):\n",
    "        if np.all(image_np[y, :] <= black_threshold):\n",
    "            bottom += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Detect left\n",
    "    for x in range(w):\n",
    "        if np.all(image_np[:, x] <= black_threshold):\n",
    "            left += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Detect right\n",
    "    for x in range(w-1, -1, -1):\n",
    "        if np.all(image_np[:, x] <= black_threshold):\n",
    "            right += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return top, bottom, left, right\n",
    "\n",
    "def crop_black_borders(image_pil, black_threshold=10):\n",
    "    \"\"\"\n",
    "    Crop black borders independently from each edge.\n",
    "\n",
    "    Args:\n",
    "        image_pil: PIL.Image object (RGB or grayscale).\n",
    "        black_threshold: Maximum pixel value considered \"black\" (0-255).\n",
    "\n",
    "    Returns:\n",
    "        Cropped PIL.Image object.\n",
    "    \"\"\"\n",
    "    top, bottom, left, right = detect_black_border_depths(image_pil, black_threshold)\n",
    "    w, h = image_pil.size\n",
    "\n",
    "    # Calculate new box\n",
    "    left_crop = left\n",
    "    upper_crop = top\n",
    "    right_crop = w - right\n",
    "    lower_crop = h - bottom\n",
    "\n",
    "    if left_crop >= right_crop or upper_crop >= lower_crop:\n",
    "        # If everything is cropped away, return original (or could raise an error)\n",
    "        print(\"Warning: Cropping would remove entire image. Returning original.\")\n",
    "        return image_pil\n",
    "\n",
    "    return image_pil.crop((left_crop, upper_crop, right_crop, lower_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nx660PVOXWKD"
   },
   "outputs": [],
   "source": [
    "def torch_image_shape(image):\n",
    "  np_img = image.cpu().permute(1, 2, 0).numpy()\n",
    "  h, w = np_img.shape[:2]\n",
    "  return h, w\n",
    "\n",
    "def LightGlue_diagonal_matching(\n",
    "    img_path1,\n",
    "    img_path2,\n",
    "    basepath_img2,\n",
    "    path_list,\n",
    "    i_value,\n",
    "    matrix_size,\n",
    "    output_dir=f\"./lightglue_{kct}_output\",\n",
    "    ransac_thresholding=100,\n",
    "    percentage_of_image_used=1.0,\n",
    "\n",
    "):\n",
    "  left_gray, left_origin, left_rgb = read_image(img_path1, 0.7)\n",
    "  right_gray, right_origin, right_rgb = read_image(img_path2, 0.7)\n",
    "\n",
    "  # right_height, right_width = img_path2.shape[:2]\n",
    "  # new_height = int(left_height * percentage_of_image_used)\n",
    "  # new_width = int(left_width * percentage_of_image_used)\n",
    "\n",
    "  image0 = load_image(img_path1).cuda()\n",
    "  image1 = load_image(img_path2).cuda()\n",
    "\n",
    "  image0 = resize_torch(image0)\n",
    "  image1 = resize_torch(image1)\n",
    "\n",
    "  # image0 = keep_top_left_percent(image0, percentage_of_image_used)\n",
    "  image1 = keep_top_left_percent(image1, percentage_of_image_used)\n",
    "\n",
    "  poz_h, poz_w, nr_h, nr_w = poz_list(basepath_img2, path_list)\n",
    "\n",
    "  # poz_h, poz_w, nr_h, nr_w = poz(matrix_size, i_value)\n",
    "\n",
    "  print(f\"We want to crop the matrix crop {(poz_h, poz_w)} out of a {matrix_size - 1, matrix_size - 1} matrix!\")\n",
    "\n",
    "  h, w = torch_image_shape(image0)\n",
    "\n",
    "  print(f\"Image size of {h, w}\")\n",
    "\n",
    "  h_size, w_size = h // nr_h, w // nr_w\n",
    "\n",
    "  print(f\"Tile size of {(h_size, w_size)}\")\n",
    "\n",
    "  matches = []\n",
    "\n",
    "  factor = 0\n",
    "\n",
    "  while len(matches) < 10:\n",
    "\n",
    "    top_left_h, top_left_w = int(h_size * max(0, poz_h - 0.75 - factor)), int(w_size * max(0, poz_w - 0.75 - factor))\n",
    "\n",
    "    bottom_right_h, bottom_right_w = int(min(h, h_size * (poz_h + 1.5 + factor))), int(min(w, w_size * (poz_w + 1.5 + factor)))\n",
    "\n",
    "    print(f\"Box proposed is {(top_left_h, top_left_w, bottom_right_h, bottom_right_w)}\")\n",
    "\n",
    "    if factor != 0:\n",
    "      image0 = load_image(img_path1).cuda()\n",
    "      image0 = resize_torch(image0)\n",
    "    image0 = crop_tensor_image(image0, top_left_h, top_left_w, bottom_right_h, bottom_right_w)\n",
    "\n",
    "    # cropped = crop_tensor_image(image0, top_left_h, top_left_w, bottom_right_h, bottom_right_w)\n",
    "    save_image(image0, f\"00000_{i_value}_{factor}.png\")\n",
    "    save_image(image1, f\"00001_{i_value}_{factor}.png\")\n",
    "\n",
    "    # extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()  # load the extractor\n",
    "    # matcher = LightGlue(features='superpoint').eval().cuda()  # load the matcher\n",
    "    # extractor = SuperPoint(max_num_keypoints=1024).cuda()\n",
    "    # matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "    extractor = SuperPoint(max_num_keypoints=None).cuda()\n",
    "    matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "    # extractor = DISK(max_num_keypoints=2048).eval().cuda()\n",
    "    # matcher = LightGlue(features='disk', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "    # extractor = SIFT(max_num_keypoints=None).eval().cuda()\n",
    "    # matcher = LightGlue(features='sift', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "    # extractor = SIFT(max_num_keypoints=1024).eval().cuda()\n",
    "    # matcher = LightGlue(features='sift', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "    feats0 = extractor.extract(image0)\n",
    "    feats1 = extractor.extract(image1)\n",
    "\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]\n",
    "    matches = matches01['matches']\n",
    "    points0 = feats0['keypoints'][matches[..., 0]]\n",
    "    points1 = feats1['keypoints'][matches[..., 1]]\n",
    "\n",
    "    matches = np.concatenate((points0.cpu(), points1.cpu()), axis=1)\n",
    "\n",
    "    print(f\"\\n\\n\\nAvem {len(matches)} matches!\\n\\n\\n\")\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "      matches[i][0] += top_left_w\n",
    "      matches[i][1] += top_left_h\n",
    "\n",
    "    factor = factor + 0.25\n",
    "\n",
    "    if factor > 2:\n",
    "      break\n",
    "  # height = left_rgb.shape[0] + right_rgb.shape[0]\n",
    "  # width = left_rgb.shape[1] + right_rgb.shape[1]\n",
    "  # total_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "  # pos1 = (0, 0)  # top-left corner for left image\n",
    "  # pos2 = (left_rgb.shape[1], left_rgb.shape[0])  # place right image diagonally\n",
    "\n",
    "  # # Paste the images onto the canvas\n",
    "  # total_img[pos1[1]:pos1[1]+left_rgb.shape[0], pos1[0]:pos1[0]+left_rgb.shape[1]] = left_rgb\n",
    "  # total_img[pos2[1]:pos2[1]+right_rgb.shape[0], pos2[0]:pos2[0]+right_rgb.shape[1]] = right_rgb\n",
    "\n",
    "  # # Plot the matches on the composite image using the corresponding positions.\n",
    "  # plot_matches(matches, total_img, pos1=pos1, pos2=pos2)\n",
    "\n",
    "  inliers, H = ransac(matches, 100, 2000)\n",
    "\n",
    "  kaze_stitched = stitch_img(left_rgb, right_rgb, H)\n",
    "\n",
    "  kaze_stitched_uint8 = (kaze_stitched * 255).astype(np.uint8)\n",
    "  image_pil = Image.fromarray(kaze_stitched_uint8)\n",
    "\n",
    "  output_filename = f\"0000-{os.path.splitext(os.path.basename(img_path2))[0]}_LightGlue_{percentage_of_image_used}.jpg\"\n",
    "  output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "  print(f\"Saving at {output_filepath}\")\n",
    "\n",
    "  cropped_image = crop_black_borders(image_pil, black_threshold=10)\n",
    "\n",
    "  cropped_image.save(output_filepath, \"JPEG\", quality=95)\n",
    "\n",
    "  # border_depth = detect_black_border_depth(image_pil)\n",
    "\n",
    "  # print(f\"Detected black border depth: {border_depth} pixels\")\n",
    "\n",
    "  # # Optional: crop automatically if needed\n",
    "  # if border_depth > 0:\n",
    "  #     w, h = image_pil.size\n",
    "  #     cropped = image_pil.crop((border_depth, border_depth, w - border_depth, h - border_depth))\n",
    "  #     cropped.save(output_filepath, \"JPEG\", quality=95)\n",
    "  # else:\n",
    "  #     image_pil.save(output_filepath, \"JPEG\", quality=95)\n",
    "\n",
    "  return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0B8AHLwTuEj"
   },
   "outputs": [],
   "source": [
    "def torch_image_shape(image):\n",
    "  np_img = image.cpu().permute(1, 2, 0).numpy()\n",
    "  h, w = np_img.shape[:2]\n",
    "  return h, w\n",
    "\n",
    "def LightGlue_matrix_scan_diagonal_matching(\n",
    "    img_path1,\n",
    "    img_path2,\n",
    "    basepath_img2,\n",
    "    path_list,\n",
    "    i_value,\n",
    "    matrix_size,\n",
    "    output_dir=f\"./lightglue_{kct}_output\",\n",
    "    ransac_thresholding=100,\n",
    "    percentage_of_image_used=1.0,\n",
    "\n",
    "):\n",
    "\n",
    "  poz_h, poz_w, nr_h, nr_w = poz_list(basepath_img2, path_list)\n",
    "\n",
    "  print(f\"We want to crop the matrix crop {(poz_h, poz_w)} out of a {matrix_size - 1, matrix_size - 1} matrix!\")\n",
    "  print(f\"{nr_h}, {nr_w}\")\n",
    "\n",
    "  matches_maxx = []\n",
    "\n",
    "  # for iii in range(0, nr_h * 10 - 5, 5):\n",
    "  #   for jjj in range(0, nr_w * 10 - 5, 5):\n",
    "  #     i = iii / 10\n",
    "  #     j = jjj / 10\n",
    "  for i in range(nr_h):\n",
    "    for j in range(nr_w):\n",
    "      torch.cuda.empty_cache()\n",
    "      left_gray, left_origin, left_rgb = read_image(img_path1, 0.8)\n",
    "      right_gray, right_origin, right_rgb = read_image(img_path2, 0.8)\n",
    "\n",
    "      # right_height, right_width = img_path2.shape[:2]\n",
    "      # new_height = int(left_height * percentage_of_image_used)\n",
    "      # new_width = int(left_width * percentage_of_image_used)\n",
    "\n",
    "      image0 = load_image(img_path1).cuda()\n",
    "      image1 = load_image(img_path2).cuda()\n",
    "\n",
    "      image0 = resize_torch(image0, 0.8)\n",
    "      image1 = resize_torch(image1, 0.8)\n",
    "\n",
    "      # image0 = keep_top_left_percent(image0, percentage_of_image_used)\n",
    "      image1 = keep_top_left_percent(image1, percentage_of_image_used)\n",
    "\n",
    "      h, w = torch_image_shape(image0)\n",
    "\n",
    "      print(f\"Image size of {h, w}\")\n",
    "\n",
    "      h_size, w_size = h // nr_h, w // nr_w\n",
    "\n",
    "      print(f\"Tile size of {(h_size, w_size)}\")\n",
    "\n",
    "      flag = True\n",
    "\n",
    "      print(f\"h_size = {h_size}\")\n",
    "      print(f\"w_size = {w_size}\")\n",
    "\n",
    "      print(f\"i = {i}\")\n",
    "      print(f\"j = {j}\")\n",
    "      top_left_h = int(max(0, (j * h_size) - (h_size * 0.65)))\n",
    "      top_left_w = int(max(0, (i * w_size) - (w_size * 0.65)))\n",
    "\n",
    "      bottom_right_h = int(min(h, ((j + 1) * h_size) + (0.65 * h_size)))\n",
    "      bottom_right_w = int(min(w, ((i + 1) * w_size) + (0.65 * w_size)))\n",
    "\n",
    "      print(f\"Box proposed is {(top_left_h, top_left_w, bottom_right_h, bottom_right_w)}\")\n",
    "\n",
    "      image0 = crop_tensor_image(image0, top_left_h, top_left_w, bottom_right_h, bottom_right_w)\n",
    "\n",
    "      # cropped = crop_tensor_image(image0, top_left_h, top_left_w, bottom_right_h, bottom_right_w)\n",
    "      save_image(image0, f\"00000_{i_value}_{i}_{j}.png\")\n",
    "      save_image(image1, f\"00001_{i_value}.png\")\n",
    "\n",
    "      # extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()  # load the extractor\n",
    "      # matcher = LightGlue(features='superpoint').eval().cuda()  # load the matcher\n",
    "      # extractor = SuperPoint(max_num_keypoints=1024).cuda()\n",
    "      # matcher = LightGlue(features='superpoint', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "      # extractor = SuperPoint(max_num_keypoints=None).cuda()\n",
    "      # matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "      # extractor = DISK(max_num_keypoints=2048).eval().cuda()\n",
    "      # matcher = LightGlue(features='disk', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "      extractor = SIFT(max_num_keypoints=None).eval().cuda()\n",
    "      matcher = LightGlue(features='sift', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "      # extractor = SIFT(max_num_keypoints=1024).eval().cuda()\n",
    "      # matcher = LightGlue(features='sift', depth_confidence=0.9, width_confidence=0.95).cuda()\n",
    "\n",
    "      try:\n",
    "        feats0 = extractor.extract(image0)\n",
    "        feats1 = extractor.extract(image1)\n",
    "\n",
    "        matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "        feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]\n",
    "        matches = matches01['matches']\n",
    "        points0 = feats0['keypoints'][matches[..., 0]]\n",
    "        points1 = feats1['keypoints'][matches[..., 1]]\n",
    "\n",
    "        matches = np.concatenate((points0.cpu(), points1.cpu()), axis=1)\n",
    "      except Exception as e:\n",
    "        print(f\"While doing Deep Learning matching got exception: {e}\")\n",
    "        matches = []\n",
    "\n",
    "\n",
    "      print(f\"\\n\\n\\nAvem {len(matches)} matches!\\n\\n\\n\")\n",
    "\n",
    "      for ii in range(len(matches)):\n",
    "        matches[ii][0] += top_left_w\n",
    "        matches[ii][1] += top_left_h\n",
    "\n",
    "      if len(matches) > len(matches_maxx):\n",
    "        print(\"Updated maxx matches!\")\n",
    "        matches_maxx = matches\n",
    "\n",
    "      # if len(matches_maxx) > 200:\n",
    "      #   break\n",
    "  # height = left_rgb.shape[0] + right_rgb.shape[0]\n",
    "  # width = left_rgb.shape[1] + right_rgb.shape[1]\n",
    "  # total_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "  # pos1 = (0, 0)  # top-left corner for left image\n",
    "  # pos2 = (left_rgb.shape[1], left_rgb.shape[0])  # place right image diagonally\n",
    "\n",
    "  # # Paste the images onto the canvas\n",
    "  # total_img[pos1[1]:pos1[1]+left_rgb.shape[0], pos1[0]:pos1[0]+left_rgb.shape[1]] = left_rgb\n",
    "  # total_img[pos2[1]:pos2[1]+right_rgb.shape[0], pos2[0]:pos2[0]+right_rgb.shape[1]] = right_rgb\n",
    "\n",
    "  # # Plot the matches on the composite image using the corresponding positions.\n",
    "  # plot_matches(matches, total_img, pos1=pos1, pos2=pos2)\n",
    "\n",
    "  inliers, H = ransac(matches_maxx, 100, 2000)\n",
    "\n",
    "  kaze_stitched = stitch_img(left_rgb, right_rgb, H)\n",
    "\n",
    "  kaze_stitched_uint8 = (kaze_stitched * 255).astype(np.uint8)\n",
    "  image_pil = Image.fromarray(kaze_stitched_uint8)\n",
    "\n",
    "  output_filename = f\"0000-{os.path.splitext(os.path.basename(img_path2))[0]}_LightGlue_{percentage_of_image_used}.jpg\"\n",
    "  output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "  print(f\"Saving at {output_filepath}\")\n",
    "\n",
    "  cropped_image = crop_black_borders(image_pil, black_threshold=10)\n",
    "\n",
    "  cropped_image.save(output_filepath, \"JPEG\", quality=95)\n",
    "\n",
    "  # border_depth = detect_black_border_depth(image_pil)\n",
    "\n",
    "  # print(f\"Detected black border depth: {border_depth} pixels\")\n",
    "\n",
    "  # # Optional: crop automatically if needed\n",
    "  # if border_depth > 0:\n",
    "  #     w, h = image_pil.size\n",
    "  #     cropped = image_pil.crop((border_depth, border_depth, w - border_depth, h - border_depth))\n",
    "  #     cropped.save(output_filepath, \"JPEG\", quality=95)\n",
    "  # else:\n",
    "  #     image_pil.save(output_filepath, \"JPEG\", quality=95)\n",
    "\n",
    "  return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fdaMRyz2mkv"
   },
   "outputs": [],
   "source": [
    "def torch_image_shape(image):\n",
    "  np_img = image.cpu().permute(1, 2, 0).numpy()\n",
    "  h, w = np_img.shape[:2]\n",
    "  return h, w\n",
    "\n",
    "def extract_submatrix(flat_list, shape, x1, y1, x2, y2):\n",
    "    rows, cols = shape\n",
    "    # Adjust for 1-based indexing\n",
    "    x1 -= 1\n",
    "    y1 -= 1\n",
    "    x2 -= 1\n",
    "    y2 -= 1\n",
    "\n",
    "    # Extract and flatten the submatrix directly from flat list\n",
    "    result = []\n",
    "    for i in range(x1, x2 + 1):\n",
    "        start = i * cols + y1\n",
    "        end = i * cols + y2 + 1\n",
    "        result.extend(flat_list[start:end])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def SuperGlue_merge(\n",
    "    img_path1,\n",
    "    img_path2,\n",
    "    output_dir=f\"./lightglue_{kct}_output\",\n",
    "    ransac_thresholding=100,\n",
    "    percentage_of_image_used=1.0,\n",
    "):\n",
    "    left_gray, left_origin, left_rgb = read_image(img_path1, 0.8)\n",
    "    right_gray, right_origin, right_rgb = read_image(img_path2, 0.8)\n",
    "\n",
    "    image0 = load_image(img_path1).cuda()\n",
    "    image1 = load_image(img_path2).cuda()\n",
    "\n",
    "    image0 = resize_torch(image0)\n",
    "    image1 = resize_torch(image1)\n",
    "\n",
    "    # image0 = keep_top_left_percent(image0, percentage_of_image_used)\n",
    "    image1 = keep_top_left_percent(image1, percentage_of_image_used)\n",
    "\n",
    "    extractor = SuperPoint(max_num_keypoints=None).cuda()\n",
    "    matcher = LightGlue(features='superpoint', depth_confidence=-1, width_confidence=-1).cuda()\n",
    "\n",
    "    feats0 = extractor.extract(image0)\n",
    "    feats1 = extractor.extract(image1)\n",
    "\n",
    "    matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]\n",
    "    matches = matches01['matches']\n",
    "    points0 = feats0['keypoints'][matches[..., 0]]\n",
    "    points1 = feats1['keypoints'][matches[..., 1]]\n",
    "\n",
    "    matches = np.concatenate((points0.cpu(), points1.cpu()), axis=1)\n",
    "\n",
    "    print(f\"\\n\\n\\nAvem {len(matches)} matches!\\n\\n\\n\")\n",
    "\n",
    "    inliers, H = ransac(matches, 100, 2000)\n",
    "\n",
    "    kaze_stitched = stitch_img(left_rgb, right_rgb, H)\n",
    "\n",
    "    kaze_stitched_uint8 = (kaze_stitched * 255).astype(np.uint8)\n",
    "    image_pil = Image.fromarray(kaze_stitched_uint8)\n",
    "\n",
    "    output_filename = f\"0000-{os.path.splitext(os.path.basename(img_path2))[0]}_LightGlue_{percentage_of_image_used}.jpg\"\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    print(f\"Saving at {output_filepath}\")\n",
    "\n",
    "    cropped_image = crop_black_borders(image_pil, black_threshold=10)\n",
    "\n",
    "    cropped_image.save(output_filepath, \"JPEG\", quality=95)\n",
    "\n",
    "    return output_filepath\n",
    "\n",
    "\n",
    "def LightGlue_divide_et_impera_matching(\n",
    "    path_list,\n",
    "    matrix_shape,\n",
    "    output_dir=f\"./lightglue_{kct}_output\",\n",
    "    ransac_thresholding=100,\n",
    "    percentage_of_image_used=1.0,\n",
    "\n",
    "):\n",
    "\n",
    "  if matrix_shape[0] == 1 and matrix_shape[1] == 1:\n",
    "    return path_list[0]\n",
    "\n",
    "  if matrix_shape[0] == 1:\n",
    "    center_h = matrix_shape[0] // 2\n",
    "\n",
    "    path_list_top = extract_submatrix(\n",
    "        path_list,\n",
    "        matrix_shape,\n",
    "        1, 1,\n",
    "        center_h, 1\n",
    "    )\n",
    "    path_top = LightGlue_divide_et_impera_matching(\n",
    "        path_list_top,\n",
    "         (matrix_shape[0] // 2, 1),\n",
    "        output_dir,\n",
    "        ransac_thresholding,\n",
    "        percentage_of_image_used\n",
    "    )\n",
    "\n",
    "    path_list_bottom = extract_submatrix(\n",
    "        path_list,\n",
    "        matrix_shape,\n",
    "        center_h + 1, 1,\n",
    "        matrix_shape[0], 1\n",
    "    )\n",
    "    path_bottom = LightGlue_divide_et_impera_matching(\n",
    "        path_list_bottom,\n",
    "         (matrix_shape[0] - (matrix_shape[0] // 2), 1),\n",
    "        output_dir,\n",
    "        ransac_thresholding,\n",
    "        percentage_of_image_used\n",
    "    )\n",
    "\n",
    "    return SuperGlue_merge(\n",
    "        path_top,\n",
    "        path_bottom,\n",
    "        output_dir,\n",
    "        ransac_thresholding,\n",
    "        percentage_of_image_used\n",
    "    )\n",
    "\n",
    "  if matrix_shape[1] == 1:\n",
    "    center_w = matrix_shape[1] // 2\n",
    "\n",
    "    path_list_left = extract_submatrix(\n",
    "        path_list,\n",
    "        matrix_shape,\n",
    "        1, 1,\n",
    "        1, center_w\n",
    "    )\n",
    "    path_left = LightGlue_divide_et_impera_matching(\n",
    "        path_list_left,\n",
    "         (1, matrix_shape[1] // 2),\n",
    "        output_dir,\n",
    "        ransac_thresholding,\n",
    "        percentage_of_image_used\n",
    "    )\n",
    "\n",
    "    path_list_right = extract_submatrix(\n",
    "        path_list,\n",
    "        matrix_shape,\n",
    "        1, center_w + 1,\n",
    "        1, matrix_shape[1]\n",
    "    )\n",
    "    path_right = LightGlue_divide_et_impera_matching(\n",
    "        path_list_right,\n",
    "         (1, matrix_shape[1] - (matrix_shape[1] // 2)),\n",
    "        output_dir,\n",
    "        ransac_thresholding,\n",
    "        percentage_of_image_used\n",
    "    )\n",
    "\n",
    "    return SuperGlue_merge(\n",
    "        path_left,\n",
    "        path_right,\n",
    "        output_dir,\n",
    "        ransac_thresholding,\n",
    "        percentage_of_image_used\n",
    "    )\n",
    "\n",
    "\n",
    "  center_h, center_w = matrix_shape[0] // 2, matrix_shape[1] // 2\n",
    "\n",
    "  path_list_top_left = extract_submatrix(path_list, matrix_shape, 1, 1, center_h, center_w)\n",
    "  path_top_left = LightGlue_divide_et_impera_matching(path_list_top_left, (matrix_shape[0] // 2, matrix_shape[1] // 2), output_dir, ransac_thresholding, percentage_of_image_used)\n",
    "\n",
    "  path_list_top_right = extract_submatrix(path_list, matrix_shape, 1, center_w + 1, center_h, matrix_shape[1])\n",
    "  path_top_right = LightGlue_divide_et_impera_matching(path_list_top_right, (matrix_shape[0] // 2, matrix_shape[1] - (matrix_shape[1] // 2)), output_dir, ransac_thresholding, percentage_of_image_used)\n",
    "\n",
    "  path_list_bottom_left = extract_submatrix(path_list, matrix_shape, center_h + 1, 1, matrix_shape[0], center_w)\n",
    "  path_bottom_left = LightGlue_divide_et_impera_matching(path_list_bottom_left, (matrix_shape[0] - (matrix_shape[0] // 2), matrix_shape[1] // 2), output_dir, ransac_thresholding, percentage_of_image_used)\n",
    "\n",
    "  path_list_bottom_right = extract_submatrix(path_list, matrix_shape, center_h + 1, center_w + 1, matrix_shape[0], matrix_shape[1])\n",
    "  path_bottom_right = LightGlue_divide_et_impera_matching(path_list_bottom_left, (matrix_shape[0] - (matrix_shape[0] // 2), matrix_shape[1] - (matrix_shape[1] // 2)), output_dir, ransac_thresholding, percentage_of_image_used)\n",
    "\n",
    "  path_top = SuperGlue_merge(path_top_left, path_top_right, output_dir, ransac_thresholding, percentage_of_image_used)\n",
    "  path_bottom = SuperGlue_merge(path_bottom_left, path_bottom_right, output_dir, ransac_thresholding, percentage_of_image_used)\n",
    "\n",
    "  return SuperGlue_merge(path_top, path_bottom, output_dir, ransac_thresholding, percentage_of_image_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjuwiG1dJA__"
   },
   "outputs": [],
   "source": [
    "def stitch_img(left, right, H):\n",
    "    # print(\"Stitching image ...\")\n",
    "\n",
    "    # Normalize images to float in [0,1]\n",
    "    left = cv2.normalize(left.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    right = cv2.normalize(right.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Get dimensions of both images\n",
    "    height_l, width_l, _ = left.shape\n",
    "    height_r, width_r, _ = right.shape\n",
    "\n",
    "    # Compute corners for the left image and transform them using H\n",
    "    corners_left = np.array([[0, 0, 1],\n",
    "                             [width_l, 0, 1],\n",
    "                             [width_l, height_l, 1],\n",
    "                             [0, height_l, 1]]).T  # shape (3,4)\n",
    "    warped_corners_left = H @ corners_left\n",
    "    warped_corners_left /= warped_corners_left[2, :]  # Normalize homogeneous coordinates\n",
    "\n",
    "    # Compute corners for the right image (identity transform)\n",
    "    corners_right = np.array([[0, 0, 1],\n",
    "                              [width_r, 0, 1],\n",
    "                              [width_r, height_r, 1],\n",
    "                              [0, height_r, 1]]).T  # shape (3,4)\n",
    "\n",
    "    # Combine corners to find overall bounds\n",
    "    all_x = np.concatenate((warped_corners_left[0, :], corners_right[0, :]))\n",
    "    all_y = np.concatenate((warped_corners_left[1, :], corners_right[1, :]))\n",
    "\n",
    "    min_x, max_x = np.min(all_x), np.max(all_x)\n",
    "    min_y, max_y = np.min(all_y), np.max(all_y)\n",
    "\n",
    "    # Create a translation matrix to shift all images so that no coordinate is negative\n",
    "    tx = -min_x if min_x < 0 else 0\n",
    "    ty = -min_y if min_y < 0 else 0\n",
    "    translation_mat = np.array([[1, 0, tx],\n",
    "                                [0, 1, ty],\n",
    "                                [0, 0, 1]])\n",
    "\n",
    "    # New canvas size: use ceiling to ensure full coverage\n",
    "    width_new = int(np.ceil(max_x - min_x))\n",
    "    height_new = int(np.ceil(max_y - min_y))\n",
    "    size = (width_new, height_new)\n",
    "\n",
    "    # Warp left image with the composite transform: translation_mat @ H\n",
    "    warped_left = cv2.warpPerspective(left, translation_mat @ H, size)\n",
    "    # Warp right image with just the translation matrix (identity warp + translation)\n",
    "    warped_right = cv2.warpPerspective(right, translation_mat, size)\n",
    "\n",
    "    # Vectorized blending:\n",
    "    # Create masks where any channel is non-zero (assumed as non-black)\n",
    "    mask_left = np.any(warped_left != 0, axis=2)\n",
    "    mask_right = np.any(warped_right != 0, axis=2)\n",
    "\n",
    "    # Initialize the stitched image as black\n",
    "    stitch_image = np.zeros_like(warped_left)\n",
    "\n",
    "    # Pixels only from left image\n",
    "    only_left = mask_left & ~mask_right\n",
    "    stitch_image[only_left] = warped_left[only_left]\n",
    "\n",
    "    # Pixels only from right image\n",
    "    only_right = mask_right & ~mask_left\n",
    "    stitch_image[only_right] = warped_right[only_right]\n",
    "\n",
    "    # Pixels where both images contribute (average the pixel values)\n",
    "    both = mask_left & mask_right\n",
    "    stitch_image[both] = (warped_left[both] + warped_right[both]) / 2\n",
    "\n",
    "    return stitch_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaPGX_NXVxZh",
    "outputId": "90a39300-e297-4096-e061-ee5f5752f10f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'content'\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "cd content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXX9WNGvYziU",
    "outputId": "2fbd6b8e-62dc-4d5e-85ad-4c609c693266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.jpg', '0001.jpg', '0002.jpg', '0003.jpg', '0004.jpg', '0005.jpg', '0006.jpg', '0007.jpg', '0008.jpg', '0009.jpg', '0010.jpg', '0011.jpg', '0012.jpg', '0013.jpg', '0014.jpg', '0015.jpg', '0016.jpg', '0017.jpg', '0018.jpg', '0019.jpg', '0020.jpg', '0021.jpg', '0022.jpg', '0023.jpg', '0024.jpg', '0025.jpg', '0026.jpg', '0027.jpg', '0028.jpg', '0029.jpg', '0030.jpg', '0031.jpg', '0032.jpg', '0033.jpg', '0034.jpg', '0035.jpg', '0036.jpg', '0037.jpg', '0038.jpg', '0039.jpg', '0040.jpg', '0041.jpg', '0042.jpg', '0043.jpg', '0044.jpg', '0045.jpg', '0046.jpg', '0047.jpg', '0048.jpg', '0049.jpg', '0050.jpg', '0051.jpg', '0052.jpg', '0053.jpg', '0054.jpg', '0055.jpg', '0056.jpg', '0057.jpg', '0058.jpg', '0059.jpg', '0060.jpg', '0061.jpg', '0062.jpg', '0063.jpg', '0064.jpg', '0065.jpg', '0066.jpg', '0067.jpg', '0068.jpg', '0069.jpg', '0070.jpg', '0071.jpg', '0072.jpg', '0073.jpg', '0074.jpg', '0075.jpg', '0076.jpg', '0077.jpg', '0078.jpg', '0079.jpg', '0080.jpg', '0081.jpg', '0082.jpg', '0083.jpg', '0084.jpg', '0085.jpg', '0086.jpg', '0087.jpg', '0088.jpg', '0089.jpg', '0090.jpg', '0091.jpg', '0092.jpg', '0093.jpg', '0094.jpg', '0095.jpg', '0096.jpg', '0097.jpg', '0098.jpg', '0099.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_path = \"./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80\"\n",
    "\n",
    "input_path = \"./drive/MyDrive/Disertatie/Patches/051-04-80-original\" #026-01-91_original\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "  os.mkdir(output_path)\n",
    "\n",
    "paths = sorted(os.listdir(input_path))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfCNldDXKku1",
    "outputId": "8761f833-ccc5-4d6a-c1d2-2d36e978b03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.jpg', '0005.jpg', '0001.jpg', '0010.jpg', '0006.jpg', '0002.jpg', '0015.jpg', '0011.jpg', '0007.jpg', '0003.jpg', '0020.jpg', '0016.jpg', '0012.jpg', '0008.jpg', '0004.jpg', '0021.jpg', '0017.jpg', '0013.jpg', '0009.jpg', '0022.jpg', '0018.jpg', '0014.jpg', '0023.jpg', '0019.jpg', '0024.jpg']\n",
      "['0000.jpg', '0001.jpg', '0005.jpg', '0006.jpg', '0002.jpg', '0007.jpg', '0010.jpg', '0011.jpg', '0012.jpg', '0003.jpg', '0008.jpg', '0013.jpg', '0015.jpg', '0016.jpg', '0017.jpg', '0018.jpg', '0004.jpg', '0009.jpg', '0014.jpg', '0019.jpg', '0020.jpg', '0021.jpg', '0022.jpg', '0023.jpg', '0024.jpg']\n"
     ]
    }
   ],
   "source": [
    "def diagonal_submatrix(k, x, y, image_paths):\n",
    "    matrix_size = k  # Assumes a 10x10 matrix\n",
    "    \"\"\"\n",
    "    Return the k×k submatrix of a width×width grid stored in `image_paths` (row-major order),\n",
    "    starting at top-left coordinate (x, y), traversed in diagonal order.\n",
    "\n",
    "    Parameters:\n",
    "        image_paths (List[str]): Flat list of image image_paths of length width×width.\n",
    "        k (int): Size of the submatrix (k rows, k columns).\n",
    "        x (int): Row index of the submatrix's top-left corner (0-based).\n",
    "        y (int): Column index of the submatrix's top-left corner (0-based).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The k×k submatrix's elements in diagonal order.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # There are 2k-1 diagonals, indexed by sum d = i+j from 0 to 2(k-1).\n",
    "    for d in range(2 * k - 1):\n",
    "        # For each diagonal, i goes from min(d, k-1) down to max(0, d-(k-1)).\n",
    "        start = min(d, k - 1)\n",
    "        end = max(0, d - (k - 1))\n",
    "        for i in range(start, end - 1, -1):\n",
    "            j = d - i\n",
    "            global_i = x + i\n",
    "            global_j = y + j\n",
    "            idx = global_i * matrix_size + global_j\n",
    "            result.append(image_paths[idx])\n",
    "    return result\n",
    "\n",
    "def get_expanding_square_order(k, x, y, image_paths):\n",
    "    matrix_size = 5  # Assumes a 10x10 matrix\n",
    "    result = []\n",
    "\n",
    "    for size in range(1, k + 1):\n",
    "        # Iterate over the new square of size `size x size`\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                xi, yj = x + i, y + j\n",
    "                if xi < matrix_size and yj < matrix_size:\n",
    "                    index = xi * matrix_size + yj\n",
    "                    coord = (i, j)\n",
    "                    # Only include the newly added positions (i == size - 1 or j == size - 1)\n",
    "                    if i == size - 1 or j == size - 1:\n",
    "                        result.append(image_paths[index])\n",
    "\n",
    "    return result\n",
    "\n",
    "print(diagonal_submatrix(5, 0, 0, paths))\n",
    "# Expected: ['0000.jpg', '0010.jpg', '0001.jpg', '0020.jpg', '0011.jpg', '0002.jpg', '0021.jpg', '0012.jpg', '0022.jpg']\n",
    "\n",
    "print(get_expanding_square_order(5, 0, 0, paths))\n",
    "# Output: ['0000.jpg', '0010.jpg', '0001.jpg', '0011.jpg', '0020.jpg', '0021.jpg', '0002.jpg', '0012.jpg', '0022.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1dtBJ6aOc90",
    "outputId": "3c296da5-7301-42be-90be-c33bd6e8f5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.jpg', '0010.jpg', '0001.jpg', '0020.jpg', '0011.jpg', '0002.jpg', '0030.jpg', '0021.jpg', '0012.jpg', '0003.jpg', '0040.jpg', '0031.jpg', '0022.jpg', '0013.jpg', '0004.jpg', '0050.jpg', '0041.jpg', '0032.jpg', '0023.jpg', '0014.jpg', '0005.jpg', '0060.jpg', '0051.jpg', '0042.jpg', '0033.jpg', '0024.jpg', '0015.jpg', '0006.jpg', '0070.jpg', '0061.jpg', '0052.jpg', '0043.jpg', '0034.jpg', '0025.jpg', '0016.jpg', '0007.jpg', '0080.jpg', '0071.jpg', '0062.jpg', '0053.jpg', '0044.jpg', '0035.jpg', '0026.jpg', '0017.jpg', '0008.jpg', '0090.jpg', '0081.jpg', '0072.jpg', '0063.jpg', '0054.jpg', '0045.jpg', '0036.jpg', '0027.jpg', '0018.jpg', '0009.jpg', '0091.jpg', '0082.jpg', '0073.jpg', '0064.jpg', '0055.jpg', '0046.jpg', '0037.jpg', '0028.jpg', '0019.jpg', '0092.jpg', '0083.jpg', '0074.jpg', '0065.jpg', '0056.jpg', '0047.jpg', '0038.jpg', '0029.jpg', '0093.jpg', '0084.jpg', '0075.jpg', '0066.jpg', '0057.jpg', '0048.jpg', '0039.jpg', '0094.jpg', '0085.jpg', '0076.jpg', '0067.jpg', '0058.jpg', '0049.jpg', '0095.jpg', '0086.jpg', '0077.jpg', '0068.jpg', '0059.jpg', '0096.jpg', '0087.jpg', '0078.jpg', '0069.jpg', '0097.jpg', '0088.jpg', '0079.jpg', '0098.jpg', '0089.jpg', '0099.jpg']\n",
      "['0000.jpg', '0010.jpg', '0001.jpg', '0020.jpg', '0011.jpg', '0002.jpg', '0030.jpg', '0021.jpg', '0012.jpg', '0003.jpg', '0040.jpg', '0031.jpg', '0022.jpg', '0013.jpg', '0004.jpg', '0041.jpg', '0032.jpg', '0023.jpg', '0014.jpg', '0042.jpg', '0033.jpg', '0024.jpg', '0043.jpg', '0034.jpg', '0044.jpg']\n"
     ]
    }
   ],
   "source": [
    "matrix_size_wanted = 10\n",
    "paths = diagonal_submatrix(matrix_size_wanted, 0, 0, paths)\n",
    "# paths = ['0000.jpg', '0001.jpg', '0002.jpg', '0010.jpg', '0011.jpg', '0012.jpg', '0020.jpg', '0021.jpg', '0022.jpg']\n",
    "print(paths)\n",
    "\n",
    "def filter_paths(paths):\n",
    "  def is_ok(x):\n",
    "    return int(x[2]) < 5 and int(x[3]) < 5\n",
    "  return [x for x in paths if is_ok(x)]\n",
    "paths = filter_paths(paths)\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UngIYj2Hs8cu",
    "outputId": "ccb7057f-4481-4d10-b9ba-6da52810b7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000.jpg', '0010.jpg', '0001.jpg', '0020.jpg', '0011.jpg', '0002.jpg', '0030.jpg', '0021.jpg', '0012.jpg', '0003.jpg', '0040.jpg', '0031.jpg', '0022.jpg', '0013.jpg', '0004.jpg', '0041.jpg', '0032.jpg', '0023.jpg', '0014.jpg', '0042.jpg', '0033.jpg', '0024.jpg', '0043.jpg', '0034.jpg', '0044.jpg']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "len_paths1 = (matrix_size_wanted * (matrix_size_wanted + 1)) // 2\n",
    "paths1 = paths[:len_paths1]\n",
    "paths2 = paths[len_paths1:][::-1]\n",
    "\n",
    "print(paths1)\n",
    "print(paths2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHvP0SzmtR0G",
    "outputId": "ef6b526b-7f66-4391-e917-32e61a5edb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0031.jpg\n",
      "0022.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def increment_filename_by_11(filepath):\n",
    "    # Extract the filename\n",
    "    # return filepath\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    # Remove the file extension and convert to integer\n",
    "    number_str = filename[:-4]  # Removes '.jpg'\n",
    "    number = int(number_str)\n",
    "\n",
    "    # Add 11\n",
    "    new_number = number + 21\n",
    "\n",
    "    # Format back to 4-digit string and add extension\n",
    "    new_filename = f\"{new_number:04}.jpg\"\n",
    "    return new_filename\n",
    "\n",
    "# Examples\n",
    "print(increment_filename_by_11(\"./path_folder/0010.jpg\"))  # Output: 0021.jpg\n",
    "print(increment_filename_by_11(\"0001.jpg\"))                # Output: 0012.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_L4IKVAAlyAX",
    "outputId": "d026e467-91b2-4699-8313-28dd214c4fd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0044.jpg\n",
      "0000.jpg\n",
      "0000-0044_LightGlue_1.0.jpg\n",
      "0\n",
      "-----------------\n",
      "0000.jpg\n",
      "0010.jpg\n",
      "0000-0000_LightGlue_1.0.jpg\n",
      "1\n",
      "-----------------\n",
      "We want to crop the matrix crop (1, 0) out of a (4, 4) matrix!\n",
      "1, 1\n",
      "Is tensor\n",
      "Image size of (1375, 1843)\n",
      "Tile size of (1375, 1843)\n",
      "h_size = 1375\n",
      "w_size = 1843\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1375, 1843)\n",
      "\n",
      "\n",
      "\n",
      "Avem 4261 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "inliers/matches: 4239/4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:29<05:43, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0031_LightGlue_1.0.jpg\n",
      "0010.jpg\n",
      "0001.jpg\n",
      "0000-0010_LightGlue_1.0.jpg\n",
      "2\n",
      "-----------------\n",
      "We want to crop the matrix crop (0, 1) out of a (4, 4) matrix!\n",
      "2, 1\n",
      "Is tensor\n",
      "Image size of (1930, 1504)\n",
      "Tile size of (965, 1504)\n",
      "h_size = 965\n",
      "w_size = 1504\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1592, 1504)\n",
      "\n",
      "\n",
      "\n",
      "Avem 3743 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (1930, 1504)\n",
      "Tile size of (965, 1504)\n",
      "h_size = 965\n",
      "w_size = 1504\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 526, 1592, 1504)\n",
      "While doing Deep Learning matching got exception: CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.03 GiB is free. Process 2817 has 38.52 GiB memory in use. Of the allocated memory 36.69 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 3685/3743\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0022_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [00:58<07:37, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001.jpg\n",
      "0020.jpg\n",
      "0000-0001_LightGlue_1.0.jpg\n",
      "3\n",
      "-----------------\n",
      "We want to crop the matrix crop (2, 0) out of a (4, 4) matrix!\n",
      "2, 2\n",
      "Is tensor\n",
      "Image size of (2048, 2656)\n",
      "Tile size of (1024, 1328)\n",
      "h_size = 1024\n",
      "w_size = 1328\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1689, 2191)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (2048, 2656)\n",
      "Tile size of (1024, 1328)\n",
      "h_size = 1024\n",
      "w_size = 1328\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (358, 0, 2048, 2191)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1194 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2048, 2656)\n",
      "Tile size of (1024, 1328)\n",
      "h_size = 1024\n",
      "w_size = 1328\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 464, 1689, 2656)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (2048, 2656)\n",
      "Tile size of (1024, 1328)\n",
      "h_size = 1024\n",
      "w_size = 1328\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (358, 464, 2048, 2656)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1120 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 1173/1194\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0041_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [01:25<07:59, 22.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0020.jpg\n",
      "0011.jpg\n",
      "0000-0020_LightGlue_1.0.jpg\n",
      "4\n",
      "-----------------\n",
      "We want to crop the matrix crop (1, 1) out of a (4, 4) matrix!\n",
      "3, 2\n",
      "Is tensor\n",
      "Image size of (2871, 2845)\n",
      "Tile size of (957, 1422)\n",
      "h_size = 957\n",
      "w_size = 1422\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1579, 2346)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1779 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2871, 2845)\n",
      "Tile size of (957, 1422)\n",
      "h_size = 957\n",
      "w_size = 1422\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (334, 0, 2536, 2346)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2208 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2871, 2845)\n",
      "Tile size of (957, 1422)\n",
      "h_size = 957\n",
      "w_size = 1422\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 497, 1579, 2845)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2255 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2871, 2845)\n",
      "Tile size of (957, 1422)\n",
      "h_size = 957\n",
      "w_size = 1422\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (334, 497, 2536, 2845)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2687 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2871, 2845)\n",
      "Tile size of (957, 1422)\n",
      "h_size = 957\n",
      "w_size = 1422\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1919, 1579, 2845)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2337 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (2871, 2845)\n",
      "Tile size of (957, 1422)\n",
      "h_size = 957\n",
      "w_size = 1422\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (334, 1919, 2536, 2845)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1148 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 2596/2687\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0032_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [02:08<09:59, 29.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0011.jpg\n",
      "0002.jpg\n",
      "0000-0011_LightGlue_1.0.jpg\n",
      "5\n",
      "-----------------\n",
      "We want to crop the matrix crop (0, 2) out of a (4, 4) matrix!\n",
      "3, 2\n",
      "Is tensor\n",
      "Image size of (2938, 2665)\n",
      "Tile size of (979, 1332)\n",
      "h_size = 979\n",
      "w_size = 1332\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1615, 2197)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (2938, 2665)\n",
      "Tile size of (979, 1332)\n",
      "h_size = 979\n",
      "w_size = 1332\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (342, 0, 2594, 2197)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (2938, 2665)\n",
      "Tile size of (979, 1332)\n",
      "h_size = 979\n",
      "w_size = 1332\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 466, 1615, 2665)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2310 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2938, 2665)\n",
      "Tile size of (979, 1332)\n",
      "h_size = 979\n",
      "w_size = 1332\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (342, 466, 2594, 2665)\n",
      "\n",
      "\n",
      "\n",
      "Avem 544 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (2938, 2665)\n",
      "Tile size of (979, 1332)\n",
      "h_size = 979\n",
      "w_size = 1332\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1798, 1615, 2665)\n",
      "\n",
      "\n",
      "\n",
      "Avem 4386 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (2938, 2665)\n",
      "Tile size of (979, 1332)\n",
      "h_size = 979\n",
      "w_size = 1332\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (342, 1798, 2594, 2665)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1431 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 4372/4386\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0023_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [03:02<12:03, 38.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002.jpg\n",
      "0030.jpg\n",
      "0000-0002_LightGlue_1.0.jpg\n",
      "6\n",
      "-----------------\n",
      "We want to crop the matrix crop (3, 0) out of a (4, 4) matrix!\n",
      "3, 3\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1765, 2184)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (374, 0, 2835, 2184)\n",
      "\n",
      "\n",
      "\n",
      "Avem 504 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1444, 0, 3212, 2184)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2976 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 463, 1765, 3508)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (374, 463, 2835, 3508)\n",
      "\n",
      "\n",
      "\n",
      "Avem 229 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1444, 463, 3212, 3508)\n",
      "\n",
      "\n",
      "\n",
      "Avem 604 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1787, 1765, 3973)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (374, 1787, 2835, 3973)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3212, 3973)\n",
      "Tile size of (1070, 1324)\n",
      "h_size = 1070\n",
      "w_size = 1324\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1444, 1787, 3212, 3973)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 2961/2976\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0051_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [04:09<14:13, 47.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0030.jpg\n",
      "0021.jpg\n",
      "0000-0030_LightGlue_1.0.jpg\n",
      "7\n",
      "-----------------\n",
      "We want to crop the matrix crop (2, 1) out of a (4, 4) matrix!\n",
      "4, 3\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1605, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (340, 0, 2578, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1155 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1313, 0, 3551, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1503 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 534, 1605, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (340, 534, 2578, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 563 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1313, 534, 3551, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 732 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2060, 1605, 4580)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (340, 2060, 2578, 4580)\n",
      "\n",
      "\n",
      "\n",
      "Avem 670 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1313, 2060, 3551, 4580)\n",
      "\n",
      "\n",
      "\n",
      "Avem 658 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3586, 1605, 4580)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (340, 3586, 2578, 4580)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3895, 4580)\n",
      "Tile size of (973, 1526)\n",
      "h_size = 973\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1313, 3586, 3551, 4580)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 1280/1503\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0042_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [05:28<16:10, 57.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0021.jpg\n",
      "0012.jpg\n",
      "0000-0021_LightGlue_1.0.jpg\n",
      "8\n",
      "-----------------\n",
      "We want to crop the matrix crop (1, 2) out of a (4, 4) matrix!\n",
      "4, 3\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1625, 2290)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (344, 0, 2610, 2290)\n",
      "While doing Deep Learning matching got exception: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.87 GiB is free. Process 2817 has 37.67 GiB memory in use. Of the allocated memory 36.06 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1329, 0, 3595, 2290)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 485, 1625, 3678)\n",
      "\n",
      "\n",
      "\n",
      "Avem 905 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (344, 485, 2610, 3678)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1192 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1329, 485, 3595, 3678)\n",
      "\n",
      "\n",
      "\n",
      "Avem 436 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1873, 1625, 4164)\n",
      "\n",
      "\n",
      "\n",
      "Avem 3030 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (344, 1873, 2610, 4164)\n",
      "\n",
      "\n",
      "\n",
      "Avem 3680 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1329, 1873, 3595, 4164)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1083 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3261, 1625, 4164)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2224 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (344, 3261, 2610, 4164)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1296 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (3940, 4164)\n",
      "Tile size of (985, 1388)\n",
      "h_size = 985\n",
      "w_size = 1388\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1329, 3261, 3595, 4164)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 3576/3680\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0033_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [06:55<17:45, 66.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0012.jpg\n",
      "0003.jpg\n",
      "0000-0012_LightGlue_1.0.jpg\n",
      "9\n",
      "-----------------\n",
      "We want to crop the matrix crop (0, 3) out of a (4, 4) matrix!\n",
      "4, 3\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1818, 2286)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (385, 0, 2920, 2286)\n",
      "While doing Deep Learning matching got exception: CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.87 GiB is free. Process 2817 has 37.67 GiB memory in use. Of the allocated memory 36.13 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1487, 0, 4022, 2286)\n",
      "While doing Deep Learning matching got exception: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.74 GiB is free. Process 2817 has 37.80 GiB memory in use. Of the allocated memory 36.10 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 485, 1818, 3672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (385, 485, 2920, 3672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1487, 485, 4022, 3672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1871, 1818, 4160)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2153 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (385, 1871, 2920, 4160)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1102 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1487, 1871, 4022, 4160)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3257, 1818, 4160)\n",
      "\n",
      "\n",
      "\n",
      "Avem 3642 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (385, 3257, 2920, 4160)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1078 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4408, 4160)\n",
      "Tile size of (1102, 1386)\n",
      "h_size = 1102\n",
      "w_size = 1386\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1487, 3257, 4022, 4160)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 3625/3642\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0024_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [08:32<18:56, 75.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0003.jpg\n",
      "0040.jpg\n",
      "0000-0003_LightGlue_1.0.jpg\n",
      "10\n",
      "-----------------\n",
      "We want to crop the matrix crop (4, 0) out of a (4, 4) matrix!\n",
      "4, 4\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1932, 2230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (409, 0, 3103, 2230)\n",
      "While doing Deep Learning matching got exception: CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.02 GiB is free. Process 2817 has 38.52 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1580, 0, 4274, 2230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2123 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (2751, 0, 4685, 2230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 4723 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 473, 1932, 3582)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (409, 473, 3103, 3582)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1580, 473, 4274, 3582)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1294 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (2751, 473, 4685, 3582)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1718 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1825, 1932, 4934)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (409, 1825, 3103, 4934)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1580, 1825, 4274, 4934)\n",
      "\n",
      "\n",
      "\n",
      "Avem 370 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (2751, 1825, 4685, 4934)\n",
      "\n",
      "\n",
      "\n",
      "Avem 343 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3177, 1932, 5408)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (409, 3177, 3103, 5408)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1580, 3177, 4274, 5408)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (4685, 5408)\n",
      "Tile size of (1171, 1352)\n",
      "h_size = 1171\n",
      "w_size = 1352\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (2751, 3177, 4685, 5408)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 4696/4723\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0061_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [10:50<22:05, 94.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0040.jpg\n",
      "0031.jpg\n",
      "0000-0040_LightGlue_1.0.jpg\n",
      "11\n",
      "-----------------\n",
      "We want to crop the matrix crop (3, 1) out of a (4, 4) matrix!\n",
      "5, 4\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1877, 3268)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (398, 0, 3015, 3268)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1536, 0, 4153, 3268)\n",
      "\n",
      "\n",
      "\n",
      "Avem 348 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (2674, 0, 5291, 3268)\n",
      "\n",
      "\n",
      "\n",
      "Avem 770 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 693, 1877, 5249)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (398, 693, 3015, 5249)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1536, 693, 4153, 5249)\n",
      "\n",
      "\n",
      "\n",
      "Avem 109 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (2674, 693, 5291, 5249)\n",
      "\n",
      "\n",
      "\n",
      "Avem 344 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2674, 1877, 7230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (398, 2674, 3015, 7230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1536, 2674, 4153, 7230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (2674, 2674, 5291, 7230)\n",
      "\n",
      "\n",
      "\n",
      "Avem 24 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 4655, 1877, 7927)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (398, 4655, 3015, 7927)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1536, 4655, 4153, 7927)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (2674, 4655, 5291, 7927)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 6636, 1877, 7927)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (398, 6636, 3015, 7927)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (1536, 6636, 4153, 7927)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5692, 7927)\n",
      "Tile size of (1138, 1981)\n",
      "h_size = 1138\n",
      "w_size = 1981\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (2674, 6636, 5291, 7927)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 577/770\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0052_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [13:48<26:00, 120.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0031.jpg\n",
      "0022.jpg\n",
      "0000-0031_LightGlue_1.0.jpg\n",
      "12\n",
      "-----------------\n",
      "We want to crop the matrix crop (2, 2) out of a (4, 4) matrix!\n",
      "5, 4\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1687, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (358, 0, 2710, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 290 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1381, 0, 3733, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 792 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (2404, 0, 4756, 2517)\n",
      "\n",
      "\n",
      "\n",
      "Avem 610 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 534, 1687, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (358, 534, 2710, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 656 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1381, 534, 3733, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 826 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (2404, 534, 4756, 4043)\n",
      "\n",
      "\n",
      "\n",
      "Avem 524 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2060, 1687, 5569)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (358, 2060, 2710, 5569)\n",
      "\n",
      "\n",
      "\n",
      "Avem 663 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1381, 2060, 3733, 5569)\n",
      "\n",
      "\n",
      "\n",
      "Avem 805 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (2404, 2060, 4756, 5569)\n",
      "\n",
      "\n",
      "\n",
      "Avem 533 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3586, 1687, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (358, 3586, 2710, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 191 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1381, 3586, 3733, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 219 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (2404, 3586, 4756, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 9 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5112, 1687, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (358, 5112, 2710, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (1381, 5112, 3733, 6105)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5116, 6105)\n",
      "Tile size of (1023, 1526)\n",
      "h_size = 1023\n",
      "w_size = 1526\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (2404, 5112, 4756, 6105)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 552/826\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0043_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [16:17<25:44, 128.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0022.jpg\n",
      "0013.jpg\n",
      "0000-0022_LightGlue_1.0.jpg\n",
      "13\n",
      "-----------------\n",
      "We want to crop the matrix crop (1, 3) out of a (4, 4) matrix!\n",
      "5, 4\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2103, 2602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (446, 0, 3378, 2602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1721, 0, 4653, 2602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (2996, 0, 5928, 2602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 551, 2103, 4179)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (446, 551, 3378, 4179)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1721, 551, 4653, 4179)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (2996, 551, 5928, 4179)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2128, 2103, 5756)\n",
      "\n",
      "\n",
      "\n",
      "Avem 676 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (446, 2128, 3378, 5756)\n",
      "\n",
      "\n",
      "\n",
      "Avem 687 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1721, 2128, 4653, 5756)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (2996, 2128, 5928, 5756)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3705, 2103, 6308)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1991 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (446, 3705, 3378, 6308)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1344 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1721, 3705, 4653, 6308)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (2996, 3705, 5928, 6308)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5282, 2103, 6308)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1432 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (446, 5282, 3378, 6308)\n",
      "\n",
      "\n",
      "\n",
      "Avem 449 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (1721, 5282, 4653, 6308)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6377, 6308)\n",
      "Tile size of (1275, 1577)\n",
      "h_size = 1275\n",
      "w_size = 1577\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (2996, 5282, 5928, 6308)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 1934/1991\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0034_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [19:09<25:59, 141.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0013.jpg\n",
      "0004.jpg\n",
      "0000-0013_LightGlue_1.0.jpg\n",
      "14\n",
      "-----------------\n",
      "We want to crop the matrix crop (0, 4) out of a (4, 4) matrix!\n",
      "5, 4\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2166, 2438)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (459, 0, 3479, 2438)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1772, 0, 4792, 2438)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3085, 0, 6105, 2438)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 517, 2166, 3916)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (459, 517, 3479, 3916)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1772, 517, 4792, 3916)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3085, 517, 6105, 3916)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1995, 2166, 5394)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (459, 1995, 3479, 5394)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1772, 1995, 4792, 5394)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3085, 1995, 6105, 5394)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3473, 2166, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1393 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (459, 3473, 3479, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 413 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1772, 3473, 4792, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3085, 3473, 6105, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 4951, 2166, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2189 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (459, 4951, 3479, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 418 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (1772, 4951, 4792, 5912)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (6568, 5912)\n",
      "Tile size of (1313, 1478)\n",
      "h_size = 1313\n",
      "w_size = 1478\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3085, 4951, 6105, 5912)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 2168/2189\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0025_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [22:10<25:37, 153.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0004.jpg\n",
      "0041.jpg\n",
      "0000-0004_LightGlue_1.0.jpg\n",
      "15\n",
      "-----------------\n",
      "We want to crop the matrix crop (4, 1) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2504, 2564)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (531, 0, 4022, 2564)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2049, 0, 5540, 2564)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3567, 0, 7058, 2564)\n",
      "\n",
      "\n",
      "\n",
      "Avem 5 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5085, 0, 7591, 2564)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 543, 2504, 4118)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (531, 543, 4022, 4118)\n",
      "While doing Deep Learning matching got exception: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1.90 GiB is free. Process 2817 has 37.65 GiB memory in use. Of the allocated memory 35.89 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2049, 543, 5540, 4118)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2277 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3567, 543, 7058, 4118)\n",
      "\n",
      "\n",
      "\n",
      "Avem 3243 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5085, 543, 7591, 4118)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1630 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2097, 2504, 5672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (531, 2097, 4022, 5672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 20 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2049, 2097, 5540, 5672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2372 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3567, 2097, 7058, 5672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 3319 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5085, 2097, 7591, 5672)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1610 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3651, 2504, 7226)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (531, 3651, 4022, 7226)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2049, 3651, 5540, 7226)\n",
      "\n",
      "\n",
      "\n",
      "Avem 291 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3567, 3651, 7058, 7226)\n",
      "\n",
      "\n",
      "\n",
      "Avem 291 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5085, 3651, 7591, 7226)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5205, 2504, 7770)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (531, 5205, 4022, 7770)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2049, 5205, 5540, 7770)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3567, 5205, 7058, 7770)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7591, 7770)\n",
      "Tile size of (1518, 1554)\n",
      "h_size = 1518\n",
      "w_size = 1554\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5085, 5205, 7591, 7770)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 2873/3319\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0062_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [27:04<29:23, 195.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0041.jpg\n",
      "0032.jpg\n",
      "0000-0041_LightGlue_1.0.jpg\n",
      "16\n",
      "-----------------\n",
      "We want to crop the matrix crop (3, 2) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2719, 4733)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (576, 0, 4367, 4733)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2224, 0, 6015, 4733)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3872, 0, 7663, 4733)\n",
      "\n",
      "\n",
      "\n",
      "Avem 338 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5520, 0, 8241, 4733)\n",
      "\n",
      "\n",
      "\n",
      "Avem 358 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 1004, 2719, 7602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (576, 1004, 4367, 7602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2224, 1004, 6015, 7602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3872, 1004, 7663, 7602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 112 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5520, 1004, 8241, 7602)\n",
      "\n",
      "\n",
      "\n",
      "Avem 153 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 3873, 2719, 10471)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (576, 3873, 4367, 10471)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2224, 3873, 6015, 10471)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3872, 3873, 7663, 10471)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5520, 3873, 8241, 10471)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 6742, 2719, 13340)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (576, 6742, 4367, 13340)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2224, 6742, 6015, 13340)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3872, 6742, 7663, 13340)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5520, 6742, 8241, 13340)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 9611, 2719, 14346)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (576, 9611, 4367, 14346)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2224, 9611, 6015, 14346)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3872, 9611, 7663, 14346)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8241, 14346)\n",
      "Tile size of (1648, 2869)\n",
      "h_size = 1648\n",
      "w_size = 2869\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5520, 9611, 8241, 14346)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 178/358\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0053_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [34:05<35:07, 263.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0032.jpg\n",
      "0023.jpg\n",
      "0000-0032_LightGlue_1.0.jpg\n",
      "17\n",
      "-----------------\n",
      "We want to crop the matrix crop (2, 3) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 1683, 2636)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (357, 0, 2703, 2636)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1377, 0, 3723, 2636)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (2397, 0, 4743, 2636)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (3417, 0, 5100, 2636)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 559, 1683, 4234)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (357, 559, 2703, 4234)\n",
      "\n",
      "\n",
      "\n",
      "Avem 321 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1377, 559, 3723, 4234)\n",
      "\n",
      "\n",
      "\n",
      "Avem 442 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (2397, 559, 4743, 4234)\n",
      "\n",
      "\n",
      "\n",
      "Avem 325 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (3417, 559, 5100, 4234)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2157, 1683, 5832)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (357, 2157, 2703, 5832)\n",
      "\n",
      "\n",
      "\n",
      "Avem 812 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1377, 2157, 3723, 5832)\n",
      "\n",
      "\n",
      "\n",
      "Avem 915 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (2397, 2157, 4743, 5832)\n",
      "\n",
      "\n",
      "\n",
      "Avem 307 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (3417, 2157, 5100, 5832)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3755, 1683, 7430)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (357, 3755, 2703, 7430)\n",
      "\n",
      "\n",
      "\n",
      "Avem 710 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1377, 3755, 3723, 7430)\n",
      "\n",
      "\n",
      "\n",
      "Avem 751 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (2397, 3755, 4743, 7430)\n",
      "\n",
      "\n",
      "\n",
      "Avem 105 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (3417, 3755, 5100, 7430)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5353, 1683, 7992)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (357, 5353, 2703, 7992)\n",
      "\n",
      "\n",
      "\n",
      "Avem 93 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (1377, 5353, 3723, 7992)\n",
      "\n",
      "\n",
      "\n",
      "Avem 124 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (2397, 5353, 4743, 7992)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (5100, 7992)\n",
      "Tile size of (1020, 1598)\n",
      "h_size = 1020\n",
      "w_size = 1598\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (3417, 5353, 5100, 7992)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 783/915\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0044_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [37:35<28:51, 247.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0023.jpg\n",
      "0014.jpg\n",
      "0000-0023_LightGlue_1.0.jpg\n",
      "18\n",
      "-----------------\n",
      "We want to crop the matrix crop (1, 4) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2389, 2651)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (506, 0, 3837, 2651)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (1954, 0, 5285, 2651)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3402, 0, 6733, 2651)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (4850, 0, 7244, 2651)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 562, 2389, 4258)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (506, 562, 3837, 4258)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (1954, 562, 5285, 4258)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3402, 562, 6733, 4258)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (4850, 562, 7244, 4258)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2169, 2389, 5865)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (506, 2169, 3837, 5865)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (1954, 2169, 5285, 5865)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3402, 2169, 6733, 5865)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (4850, 2169, 7244, 5865)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3776, 2389, 7472)\n",
      "\n",
      "\n",
      "\n",
      "Avem 624 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (506, 3776, 3837, 7472)\n",
      "\n",
      "\n",
      "\n",
      "Avem 480 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (1954, 3776, 5285, 7472)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3402, 3776, 6733, 7472)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (4850, 3776, 7244, 7472)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5383, 2389, 8039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 2102 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (506, 5383, 3837, 8039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1113 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (1954, 5383, 5285, 8039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3402, 5383, 6733, 8039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7244, 8039)\n",
      "Tile size of (1448, 1607)\n",
      "h_size = 1448\n",
      "w_size = 1607\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (4850, 5383, 7244, 8039)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 2012/2102\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0035_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [42:03<25:21, 253.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0014.jpg\n",
      "0042.jpg\n",
      "0000-0014_LightGlue_1.0.jpg\n",
      "19\n",
      "-----------------\n",
      "We want to crop the matrix crop (4, 2) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2483, 2593)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (526, 0, 3988, 2593)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2031, 0, 5493, 2593)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3536, 0, 6998, 2593)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5041, 0, 7526, 2593)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 550, 2483, 4165)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (526, 550, 3988, 4165)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2031, 550, 5493, 4165)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3536, 550, 6998, 4165)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5041, 550, 7526, 4165)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2122, 2483, 5737)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (526, 2122, 3988, 5737)\n",
      "\n",
      "\n",
      "\n",
      "Avem 340 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2031, 2122, 5493, 5737)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1035 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3536, 2122, 6998, 5737)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1039 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5041, 2122, 7526, 5737)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3694, 2483, 7309)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (526, 3694, 3988, 7309)\n",
      "\n",
      "\n",
      "\n",
      "Avem 342 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2031, 3694, 5493, 7309)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1019 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3536, 3694, 6998, 7309)\n",
      "\n",
      "\n",
      "\n",
      "Avem 970 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5041, 3694, 7526, 7309)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5266, 2483, 7860)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (526, 5266, 3988, 7860)\n",
      "\n",
      "\n",
      "\n",
      "Avem 143 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2031, 5266, 5493, 7860)\n",
      "\n",
      "\n",
      "\n",
      "Avem 151 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3536, 5266, 6998, 7860)\n",
      "\n",
      "\n",
      "\n",
      "Avem 129 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7526, 7860)\n",
      "Tile size of (1505, 1572)\n",
      "h_size = 1505\n",
      "w_size = 1572\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5041, 5266, 7526, 7860)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 629/1039\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0063_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [46:52<22:01, 264.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0042.jpg\n",
      "0033.jpg\n",
      "0000-0042_LightGlue_1.0.jpg\n",
      "20\n",
      "-----------------\n",
      "We want to crop the matrix crop (3, 3) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2610, 4476)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (553, 0, 4192, 4476)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2135, 0, 5774, 4476)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3717, 0, 7356, 4476)\n",
      "\n",
      "\n",
      "\n",
      "Avem 145 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5299, 0, 7912, 4476)\n",
      "\n",
      "\n",
      "\n",
      "Avem 255 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 949, 2610, 7189)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (553, 949, 4192, 7189)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2135, 949, 5774, 7189)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3717, 949, 7356, 7189)\n",
      "\n",
      "\n",
      "\n",
      "Avem 146 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5299, 949, 7912, 7189)\n",
      "\n",
      "\n",
      "\n",
      "Avem 261 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 3662, 2610, 9902)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (553, 3662, 4192, 9902)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2135, 3662, 5774, 9902)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3717, 3662, 7356, 9902)\n",
      "\n",
      "\n",
      "\n",
      "Avem 175 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5299, 3662, 7912, 9902)\n",
      "\n",
      "\n",
      "\n",
      "Avem 142 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 6375, 2610, 12615)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (553, 6375, 4192, 12615)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2135, 6375, 5774, 12615)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3717, 6375, 7356, 12615)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5299, 6375, 7912, 12615)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 9088, 2610, 13568)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (553, 9088, 4192, 13568)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2135, 9088, 5774, 13568)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3717, 9088, 7356, 13568)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7912, 13568)\n",
      "Tile size of (1582, 2713)\n",
      "h_size = 1582\n",
      "w_size = 2713\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5299, 9088, 7912, 13568)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 126/261\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0054_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [53:45<20:35, 308.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0033.jpg\n",
      "0024.jpg\n",
      "0000-0033_LightGlue_1.0.jpg\n",
      "21\n",
      "-----------------\n",
      "We want to crop the matrix crop (2, 4) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2765, 3207)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (586, 0, 4441, 3207)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2262, 0, 6117, 3207)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3938, 0, 7793, 3207)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5614, 0, 8384, 3207)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 680, 2765, 5151)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (586, 680, 4441, 5151)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2262, 680, 6117, 5151)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3938, 680, 7793, 5151)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5614, 680, 8384, 5151)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2624, 2765, 7095)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (586, 2624, 4441, 7095)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2262, 2624, 6117, 7095)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3938, 2624, 7793, 7095)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5614, 2624, 8384, 7095)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 4568, 2765, 9039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 390 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (586, 4568, 4441, 9039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 391 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2262, 4568, 6117, 9039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 84 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3938, 4568, 7793, 9039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5614, 4568, 8384, 9039)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 6512, 2765, 9724)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1209 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (586, 6512, 4441, 9724)\n",
      "\n",
      "\n",
      "\n",
      "Avem 700 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2262, 6512, 6117, 9724)\n",
      "\n",
      "\n",
      "\n",
      "Avem 142 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3938, 6512, 7793, 9724)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8384, 9724)\n",
      "Tile size of (1676, 1944)\n",
      "h_size = 1676\n",
      "w_size = 1944\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5614, 6512, 8384, 9724)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 962/1209\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0045_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [59:21<15:51, 317.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0024.jpg\n",
      "0043.jpg\n",
      "0000-0024_LightGlue_1.0.jpg\n",
      "22\n",
      "-----------------\n",
      "We want to crop the matrix crop (4, 3) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2811, 2946)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (596, 0, 4515, 2946)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2300, 0, 6219, 2946)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (4004, 0, 7923, 2946)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5708, 0, 8521, 2946)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 625, 2811, 4732)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (596, 625, 4515, 4732)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2300, 625, 6219, 4732)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (4004, 625, 7923, 4732)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5708, 625, 8521, 4732)\n",
      "\n",
      "\n",
      "\n",
      "Avem 1 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 2411, 2811, 6518)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (596, 2411, 4515, 6518)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2300, 2411, 6219, 6518)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (4004, 2411, 7923, 6518)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5708, 2411, 8521, 6518)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 4197, 2811, 8304)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (596, 4197, 4515, 8304)\n",
      "\n",
      "\n",
      "\n",
      "Avem 339 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2300, 4197, 6219, 8304)\n",
      "\n",
      "\n",
      "\n",
      "Avem 651 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (4004, 4197, 7923, 8304)\n",
      "\n",
      "\n",
      "\n",
      "Avem 423 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5708, 4197, 8521, 8304)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 5983, 2811, 8930)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (596, 5983, 4515, 8930)\n",
      "\n",
      "\n",
      "\n",
      "Avem 185 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2300, 5983, 6219, 8930)\n",
      "\n",
      "\n",
      "\n",
      "Avem 640 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (4004, 5983, 7923, 8930)\n",
      "\n",
      "\n",
      "\n",
      "Avem 460 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (8521, 8930)\n",
      "Tile size of (1704, 1786)\n",
      "h_size = 1704\n",
      "w_size = 1786\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5708, 5983, 8521, 8930)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 455/651\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0064_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [1:05:01<10:47, 323.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0043.jpg\n",
      "0034.jpg\n",
      "0000-0043_LightGlue_1.0.jpg\n",
      "23\n",
      "-----------------\n",
      "We want to crop the matrix crop (3, 4) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2603, 4303)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (552, 0, 4181, 4303)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2130, 0, 5759, 4303)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3708, 0, 7337, 4303)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5286, 0, 7892, 4303)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 912, 2603, 6911)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (552, 912, 4181, 6911)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2130, 912, 5759, 6911)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3708, 912, 7337, 6911)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5286, 912, 7892, 6911)\n",
      "\n",
      "\n",
      "\n",
      "Avem 29 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 3520, 2603, 9519)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (552, 3520, 4181, 9519)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2130, 3520, 5759, 9519)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3708, 3520, 7337, 9519)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5286, 3520, 7892, 9519)\n",
      "\n",
      "\n",
      "\n",
      "Avem 197 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 6128, 2603, 12127)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (552, 6128, 4181, 12127)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2130, 6128, 5759, 12127)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3708, 6128, 7337, 12127)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5286, 6128, 7892, 12127)\n",
      "\n",
      "\n",
      "\n",
      "Avem 67 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 8736, 2603, 13040)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (552, 8736, 4181, 13040)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2130, 8736, 5759, 13040)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3708, 8736, 7337, 13040)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7892, 13040)\n",
      "Tile size of (1578, 2608)\n",
      "h_size = 1578\n",
      "w_size = 2608\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5286, 8736, 7892, 13040)\n",
      "While doing Deep Learning matching got exception: array is not broadcastable to correct shape\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 152/197\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0055_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [1:11:43<05:47, 347.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0034.jpg\n",
      "0044.jpg\n",
      "0000-0034_LightGlue_1.0.jpg\n",
      "24\n",
      "-----------------\n",
      "We want to crop the matrix crop (4, 4) out of a (4, 4) matrix!\n",
      "5, 5\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 0\n",
      "j = 0\n",
      "Box proposed is (0, 0, 2466, 2418)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 0\n",
      "j = 1\n",
      "Box proposed is (523, 0, 3961, 2418)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 0\n",
      "j = 2\n",
      "Box proposed is (2018, 0, 5456, 2418)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 0\n",
      "j = 3\n",
      "Box proposed is (3513, 0, 6951, 2418)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 0\n",
      "j = 4\n",
      "Box proposed is (5008, 0, 7477, 2418)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 1\n",
      "j = 0\n",
      "Box proposed is (0, 513, 2466, 3884)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 1\n",
      "j = 1\n",
      "Box proposed is (523, 513, 3961, 3884)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 1\n",
      "j = 2\n",
      "Box proposed is (2018, 513, 5456, 3884)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 1\n",
      "j = 3\n",
      "Box proposed is (3513, 513, 6951, 3884)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 1\n",
      "j = 4\n",
      "Box proposed is (5008, 513, 7477, 3884)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 2\n",
      "j = 0\n",
      "Box proposed is (0, 1979, 2466, 5350)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 2\n",
      "j = 1\n",
      "Box proposed is (523, 1979, 3961, 5350)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 2\n",
      "j = 2\n",
      "Box proposed is (2018, 1979, 5456, 5350)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 2\n",
      "j = 3\n",
      "Box proposed is (3513, 1979, 6951, 5350)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 2\n",
      "j = 4\n",
      "Box proposed is (5008, 1979, 7477, 5350)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 3\n",
      "j = 0\n",
      "Box proposed is (0, 3445, 2466, 6816)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 3\n",
      "j = 1\n",
      "Box proposed is (523, 3445, 3961, 6816)\n",
      "\n",
      "\n",
      "\n",
      "Avem 163 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 3\n",
      "j = 2\n",
      "Box proposed is (2018, 3445, 5456, 6816)\n",
      "\n",
      "\n",
      "\n",
      "Avem 273 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 3\n",
      "j = 3\n",
      "Box proposed is (3513, 3445, 6951, 6816)\n",
      "\n",
      "\n",
      "\n",
      "Avem 185 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 3\n",
      "j = 4\n",
      "Box proposed is (5008, 3445, 7477, 6816)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 4\n",
      "j = 0\n",
      "Box proposed is (0, 4911, 2466, 7334)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 4\n",
      "j = 1\n",
      "Box proposed is (523, 4911, 3961, 7334)\n",
      "\n",
      "\n",
      "\n",
      "Avem 397 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 4\n",
      "j = 2\n",
      "Box proposed is (2018, 4911, 5456, 7334)\n",
      "\n",
      "\n",
      "\n",
      "Avem 486 matches!\n",
      "\n",
      "\n",
      "\n",
      "Updated maxx matches!\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 4\n",
      "j = 3\n",
      "Box proposed is (3513, 4911, 6951, 7334)\n",
      "\n",
      "\n",
      "\n",
      "Avem 288 matches!\n",
      "\n",
      "\n",
      "\n",
      "Is tensor\n",
      "Image size of (7477, 7334)\n",
      "Tile size of (1495, 1466)\n",
      "h_size = 1495\n",
      "w_size = 1466\n",
      "i = 4\n",
      "j = 4\n",
      "Box proposed is (5008, 4911, 7477, 7334)\n",
      "\n",
      "\n",
      "\n",
      "Avem 0 matches!\n",
      "\n",
      "\n",
      "\n",
      "inliers/matches: 314/486\n",
      "Saving at ./drive/MyDrive/Disertatie/LightGlue/SIFT/051-04-80/0000-0065_LightGlue_1.0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:16:07<00:00, 182.69s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(paths))):\n",
    "    print(paths[i - 1], paths[i], sep=\"\\n\")\n",
    "    print(f\"0000-{paths[i - 1][:-4]}_LightGlue_1.0.jpg\")\n",
    "    print(i)\n",
    "    print(\"-----------------\")\n",
    "    if i == 0:\n",
    "        continue\n",
    "    elif i == 1:\n",
    "        stitched_img_path = LightGlue_matrix_scan_diagonal_matching(\n",
    "            img_path1 = os.path.join(input_path, increment_filename_by_11(paths[i - 1])),\n",
    "            img_path2 = os.path.join(input_path, increment_filename_by_11(paths[i])),\n",
    "            basepath_img2 = paths[i],\n",
    "            path_list = paths,\n",
    "            i_value = i,\n",
    "            matrix_size = 5,\n",
    "            output_dir=output_path,\n",
    "            ransac_thresholding=100,\n",
    "            percentage_of_image_used=1.0\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    stitched_img_path = LightGlue_matrix_scan_diagonal_matching(\n",
    "        img_path1 = os.path.join(output_path, f\"0000-{increment_filename_by_11(paths[i - 1])[:-4]}_LightGlue_1.0.jpg\"),\n",
    "        img_path2 = os.path.join(input_path, increment_filename_by_11(paths[i])),\n",
    "        basepath_img2 = paths[i],\n",
    "        path_list = paths,\n",
    "        i_value = i,\n",
    "        matrix_size = 5,\n",
    "        output_dir=output_path,\n",
    "        ransac_thresholding=100,\n",
    "        percentage_of_image_used=1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5Mg4phumMJ0"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrmaUFWbbar3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rRhB_lyNao10",
    "outputId": "583b7ee3-8782-4134-8c7c-319146640c5b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/kaze_output.zip'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "folder_path = \"./kaze_output\"  # Replace with your folder path\n",
    "zip_path = \"kaze_output.zip\"\n",
    "\n",
    "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shdY-dNFlIjD"
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree(\"./kaze_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjzq4HIJlkYa"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def calculate_averages(csv_filename):\n",
    "    rmse_total = 0\n",
    "    psnr_total = 0\n",
    "    count = 0\n",
    "\n",
    "    with open(csv_filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if not any(keyword in row['filename'] for keyword in [\"83-0084\", \"96-0097\"]):\n",
    "              rmse_total += float(row['rmse_score'])\n",
    "              psnr_total += float(row['psnr_score'])\n",
    "              count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No data found in the file.\")\n",
    "        return\n",
    "\n",
    "    rmse_avg = rmse_total / count\n",
    "    psnr_avg = psnr_total / count\n",
    "\n",
    "    print(f\"Count: {count}\")\n",
    "    print(f\"Average RMSE Score: {rmse_avg}\")\n",
    "    print(f\"Average PSNR Score: {psnr_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ve71FU6mcSOJ",
    "outputId": "e133c329-8460-4cd4-80c9-600d174dcaa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 88\n",
      "Average RMSE Score: 49.85837507247925\n",
      "Average PSNR Score: 14.199706025113324\n"
     ]
    }
   ],
   "source": [
    "calculate_averages('./kaze_output/kaze.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y7ZdmXLcWJz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
